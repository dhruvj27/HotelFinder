{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12971645,"sourceType":"datasetVersion","datasetId":8210054},{"sourceId":12971661,"sourceType":"datasetVersion","datasetId":8210066},{"sourceId":12971665,"sourceType":"datasetVersion","datasetId":8210067},{"sourceId":12992570,"sourceType":"datasetVersion","datasetId":8223803}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run this cell first\n!pip install langchain langchain_community langgraph scikit-learn surprise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:27:26.448001Z","iopub.execute_input":"2025-09-08T11:27:26.448526Z","iopub.status.idle":"2025-09-08T11:27:29.709381Z","shell.execute_reply.started":"2025-09-08T11:27:26.448493Z","shell.execute_reply":"2025-09-08T11:27:29.708589Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\nRequirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.29)\nRequirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.6.7)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\nRequirement already satisfied: surprise in /usr/local/lib/python3.11/dist-packages (0.1)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.75)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.5)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.1)\nRequirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.6.4)\nRequirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.6)\nRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (from surprise) (1.1.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\nRequirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\nRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain_community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Reinstall compatible versions together\n!pip install google-generativeai google-ai-generativelanguage langchain-google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:28:17.928568Z","iopub.execute_input":"2025-09-08T11:28:17.929200Z","iopub.status.idle":"2025-09-08T11:28:21.083283Z","shell.execute_reply.started":"2025-09-08T11:28:17.929166Z","shell.execute_reply":"2025-09-08T11:28:21.082551Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: google-ai-generativelanguage in /usr/local/lib/python3.11/dist-packages (0.6.15)\nRequirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage) (1.26.1)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.75)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.5)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.49.0rc1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.4.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (6.0.2)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (25.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.23.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.3.1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\ngemini_key = user_secrets.get_secret(\"GEMINI_API_KEY\")  # name must match exactly in Kaggle Secrets\nos.environ[\"GEMINI_API_KEY\"] = gemini_key","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:28:23.680481Z","iopub.execute_input":"2025-09-08T11:28:23.681301Z","iopub.status.idle":"2025-09-08T11:28:23.844317Z","shell.execute_reply.started":"2025-09-08T11:28:23.681265Z","shell.execute_reply":"2025-09-08T11:28:23.843539Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"Gemini key loaded?\", \"GEMINI_API_KEY\" in os.environ)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:28:25.803475Z","iopub.execute_input":"2025-09-08T11:28:25.803996Z","iopub.status.idle":"2025-09-08T11:28:25.808304Z","shell.execute_reply.started":"2025-09-08T11:28:25.803972Z","shell.execute_reply":"2025-09-08T11:28:25.807688Z"}},"outputs":[{"name":"stdout","text":"Gemini key loaded? True\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os, requests, json\nkey = os.environ.get(\"GEMINI_API_KEY\")\nif not key:\n    raise RuntimeError(\"GEMINI_API_KEY not in os.environ — load from kaggle_secrets first.\")\n\nr = requests.get(\n    \"https://generativelanguage.googleapis.com/v1/models\",\n    params={\"key\": key}\n)\nprint(\"HTTP\", r.status_code)\nprint(json.dumps(r.json(), indent=2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T07:53:10.089780Z","iopub.execute_input":"2025-09-08T07:53:10.090430Z","iopub.status.idle":"2025-09-08T07:53:10.134266Z","shell.execute_reply.started":"2025-09-08T07:53:10.090410Z","shell.execute_reply":"2025-09-08T07:53:10.133536Z"}},"outputs":[{"name":"stdout","text":"HTTP 200\n{\n  \"models\": [\n    {\n      \"name\": \"models/gemini-1.5-pro-002\",\n      \"version\": \"002\",\n      \"displayName\": \"Gemini 1.5 Pro 002\",\n      \"description\": \"Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\",\n      \"inputTokenLimit\": 2000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-1.5-pro\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini 1.5 Pro\",\n      \"description\": \"Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\",\n      \"inputTokenLimit\": 2000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-1.5-flash\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini 1.5 Flash\",\n      \"description\": \"Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\",\n      \"inputTokenLimit\": 1000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-1.5-flash-002\",\n      \"version\": \"002\",\n      \"displayName\": \"Gemini 1.5 Flash 002\",\n      \"description\": \"Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\",\n      \"inputTokenLimit\": 1000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-1.5-flash-8b\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini 1.5 Flash-8B\",\n      \"description\": \"Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\",\n      \"inputTokenLimit\": 1000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"createCachedContent\",\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-1.5-flash-8b-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini 1.5 Flash-8B 001\",\n      \"description\": \"Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\",\n      \"inputTokenLimit\": 1000000,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"createCachedContent\",\n        \"generateContent\",\n        \"countTokens\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-2.5-flash\",\n      \"version\": \"001\",\n      \"displayName\": \"Gemini 2.5 Flash\",\n      \"description\": \"Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 65536,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 64,\n      \"maxTemperature\": 2,\n      \"thinking\": true\n    },\n    {\n      \"name\": \"models/gemini-2.5-pro\",\n      \"version\": \"2.5\",\n      \"displayName\": \"Gemini 2.5 Pro\",\n      \"description\": \"Stable release (June 17th, 2025) of Gemini 2.5 Pro\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 65536,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 64,\n      \"maxTemperature\": 2,\n      \"thinking\": true\n    },\n    {\n      \"name\": \"models/gemini-2.0-flash\",\n      \"version\": \"2.0\",\n      \"displayName\": \"Gemini 2.0 Flash\",\n      \"description\": \"Gemini 2.0 Flash\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-2.0-flash-001\",\n      \"version\": \"2.0\",\n      \"displayName\": \"Gemini 2.0 Flash 001\",\n      \"description\": \"Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-2.0-flash-lite-001\",\n      \"version\": \"2.0\",\n      \"displayName\": \"Gemini 2.0 Flash-Lite 001\",\n      \"description\": \"Stable version of Gemini 2.0 Flash-Lite\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-2.0-flash-lite\",\n      \"version\": \"2.0\",\n      \"displayName\": \"Gemini 2.0 Flash-Lite\",\n      \"description\": \"Gemini 2.0 Flash-Lite\",\n      \"inputTokenLimit\": 1048576,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"createCachedContent\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 40,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/gemini-2.0-flash-preview-image-generation\",\n      \"version\": \"2.0\",\n      \"displayName\": \"Gemini 2.0 Flash Preview Image Generation\",\n      \"description\": \"Gemini 2.0 Flash Preview Image Generation\",\n      \"inputTokenLimit\": 32768,\n      \"outputTokenLimit\": 8192,\n      \"supportedGenerationMethods\": [\n        \"generateContent\",\n        \"countTokens\",\n        \"batchGenerateContent\"\n      ],\n      \"temperature\": 1,\n      \"topP\": 0.95,\n      \"topK\": 64,\n      \"maxTemperature\": 2\n    },\n    {\n      \"name\": \"models/embedding-001\",\n      \"version\": \"001\",\n      \"displayName\": \"Embedding 001\",\n      \"description\": \"Obtain a distributed representation of a text.\",\n      \"inputTokenLimit\": 2048,\n      \"outputTokenLimit\": 1,\n      \"supportedGenerationMethods\": [\n        \"embedContent\"\n      ]\n    },\n    {\n      \"name\": \"models/text-embedding-004\",\n      \"version\": \"004\",\n      \"displayName\": \"Text Embedding 004\",\n      \"description\": \"Obtain a distributed representation of a text.\",\n      \"inputTokenLimit\": 2048,\n      \"outputTokenLimit\": 1,\n      \"supportedGenerationMethods\": [\n        \"embedContent\"\n      ]\n    }\n  ]\n}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import cross_validate\nfrom langchain.tools import Tool\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.llms import OpenAI\nfrom langchain import LLMChain, PromptTemplate\nfrom typing import List, Dict, Tuple\n\n# your ContentBasedRecommender class (adapted to match column names of preprocessed file)\nclass ContentBasedRecommender:\n    def __init__(self):\n        self.hotels_df = None\n        # keep weights if you want to later weight components (not currently used in vector building)\n        self.feature_weights = {\n            'amenities': 0.35,\n            'location': 0.25,\n            'price': 0.20,\n            'star_rating': 0.15,\n            'property_type': 0.05\n        }\n        # Amenity column names — adapt to the preprocessed CSV names (prefix \"amenity_\")\n        self.amenity_features = [\n            'amenity_free_wifi', 'amenity_air_conditioning', 'amenity_parking', 'amenity_room_service',\n            'amenity_24_7_front_desk', 'amenity_restaurant', 'amenity_gym', 'amenity_pool', 'amenity_spa',\n            'amenity_business_center', 'amenity_conference_hall', 'amenity_airport_shuttle',\n            'amenity_meeting_rooms', 'amenity_vegetarian_restaurant'  # if exists\n        ]\n        self.scaler = MinMaxScaler()\n\n    def load_data(self, hotels_df: pd.DataFrame):\n        self.hotels_df = hotels_df.copy()\n        # cast amenity booleans to integers (handle missing amenities)\n        for amenity in self.amenity_features:\n            if amenity in self.hotels_df.columns:\n                # some CSVs use 0/1 or True/False strings — coerce\n                self.hotels_df[amenity] = self.hotels_df[amenity].fillna(0).astype(int)\n            else:\n                # add missing amenity column as zeros to keep vector lengths consistent\n                self.hotels_df[amenity] = 0\n\n        # create location dummies using 'city' or 'location' column if available\n        city_col = 'city' if 'city' in self.hotels_df.columns else ('location' if 'location' in self.hotels_df.columns else None)\n        if city_col is not None:\n            location_dummies = pd.get_dummies(self.hotels_df[city_col].fillna('Unknown'), prefix='city')\n            self.hotels_df = pd.concat([self.hotels_df, location_dummies], axis=1)\n        else:\n            location_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        # Normalize numeric columns for price and rating (watch column names)\n        price_col = 'price_per_night' if 'price_per_night' in self.hotels_df.columns else ('price_per_night_inr' if 'price_per_night_inr' in self.hotels_df.columns else 'price_per_night_inr')\n        rating_col = 'star_rating' if 'star_rating' in self.hotels_df.columns else 'star_rating_clean' if 'star_rating_clean' in self.hotels_df.columns else None\n\n        # Ensure numeric columns exist and fillna\n        if price_col in self.hotels_df.columns:\n            self.hotels_df[price_col] = pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(self.hotels_df[price_col].median())\n            self.hotels_df['price_normalized'] = self.scaler.fit_transform(self.hotels_df[[price_col]])\n        else:\n            self.hotels_df['price_normalized'] = 0.0\n\n        if rating_col:\n            self.hotels_df[rating_col] = pd.to_numeric(self.hotels_df[rating_col], errors='coerce').fillna(self.hotels_df[rating_col].median())\n            self.hotels_df['rating_normalized'] = self.scaler.fit_transform(self.hotels_df[[rating_col]])\n        else:\n            self.hotels_df['rating_normalized'] = 0.0\n\n        # property type dummies if present\n        property_col = 'hotel_type' if 'hotel_type' in self.hotels_df.columns else ('property_type' if 'property_type' in self.hotels_df.columns else None)\n        if property_col:\n            property_dummies = pd.get_dummies(self.hotels_df[property_col].fillna('Unknown'), prefix='property')\n            self.hotels_df = pd.concat([self.hotels_df, property_dummies], axis=1)\n        else:\n            property_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        # assemble feature columns list\n        self.feature_columns = (\n            self.amenity_features +\n            list(location_dummies.columns) +\n            ['price_normalized', 'rating_normalized'] +\n            list(property_dummies.columns)\n        )\n\n        # Build combined feature vector (as numpy array)\n        # ensure all feature columns present (if new dummies missing, add zeros)\n        for col in self.feature_columns:\n            if col not in self.hotels_df.columns:\n                self.hotels_df[col] = 0\n\n        self.hotels_df['feature_vector'] = self.hotels_df[self.feature_columns].values.tolist()\n        return self\n\n    def _create_user_profile(self, user_preferences: Dict):\n        user_vector = np.zeros(len(self.feature_columns))\n        feature_idx_map = {feature: idx for idx, feature in enumerate(self.feature_columns)}\n\n        # city\n        if 'city' in user_preferences:\n            city_feature = f\"city_{user_preferences['city']}\"\n            if city_feature in feature_idx_map:\n                user_vector[feature_idx_map[city_feature]] = 1.0\n\n        # preferred_amenities may be JSON string or list\n        if 'preferred_amenities' in user_preferences and user_preferences['preferred_amenities']:\n            pref = user_preferences['preferred_amenities']\n            if isinstance(pref, str):\n                try:\n                    preferred_amenities = json.loads(pref)\n                except Exception:\n                    preferred_amenities = [pref]\n            else:\n                preferred_amenities = pref\n            for amenity in preferred_amenities:\n                # amenity names in user_profiles may be like \"pool\" whereas our features are \"amenity_pool\"\n                col_name = amenity if amenity.startswith('amenity_') else f'amenity_{amenity}'\n                if col_name in feature_idx_map:\n                    user_vector[feature_idx_map[col_name]] = 1.0\n\n        # budget influence (approx)\n        if 'budget_min_inr' in user_preferences and 'budget_max_inr' in user_preferences:\n            # put 1 on price_normalized if within range\n            price_norm_idx = feature_idx_map.get('price_normalized')\n            if price_norm_idx is not None:\n                user_vector[price_norm_idx] = 1.0\n\n        return user_vector\n\n    def calculate_similarity(self, user_preferences: Dict, top_n: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n        if self.hotels_df is None:\n            raise ValueError(\"Load data first\")\n        user_vector = self._create_user_profile(user_preferences)\n        hotel_vectors = np.array(self.hotels_df['feature_vector'].tolist())\n        sims = cosine_similarity([user_vector], hotel_vectors)[0]\n        filtered_indices = self._apply_filters(user_preferences)\n        filtered_sims = sims[filtered_indices]\n        top_indices = filtered_indices[np.argsort(filtered_sims)[-top_n:][::-1]]\n        return top_indices, sims[top_indices]\n\n    def _apply_filters(self, user_preferences: Dict):\n        mask = pd.Series(True, index=self.hotels_df.index)\n        if 'city' in user_preferences:\n            city_col = 'city' if 'city' in self.hotels_df.columns else 'location'\n            if city_col:\n                mask &= (self.hotels_df[city_col] == user_preferences['city'])\n        if 'budget_min_inr' in user_preferences and 'budget_max_inr' in user_preferences:\n            price_col = 'price_per_night' if 'price_per_night' in self.hotels_df.columns else ('price_per_night_inr' if 'price_per_night_inr' in self.hotels_df.columns else None)\n            if price_col:\n                mask &= (pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(0) >= user_preferences['budget_min_inr']) & \\\n                        (pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(0) <= user_preferences['budget_max_inr'])\n        if 'min_star_rating' in user_preferences and 'star_rating' in self.hotels_df.columns:\n            mask &= (pd.to_numeric(self.hotels_df['star_rating'], errors='coerce').fillna(0) >= user_preferences['min_star_rating'])\n        # return indices that survive\n        return mask[mask].index\n\n    def recommend(self, user_preferences: Dict, top_n: int = 5):\n        top_indices, similarities = self.calculate_similarity(user_preferences, top_n * 2)\n        recs = []\n        for idx_num, hotel_idx in enumerate(top_indices[:top_n]):\n            hotel = self.hotels_df.iloc[hotel_idx]\n            recs.append({\n                'hotel_id': int(hotel.get('hotel_id', hotel.get('hotel_id'))),\n                'hotel_name': hotel.get('hotel_name', hotel.get('hotel_name', hotel.get('name', 'Unknown'))),\n                'city': hotel.get('city', hotel.get('location', 'Unknown')),\n                'price_per_night': float(hotel.get('price_per_night', hotel.get('price_per_night_inr', 0))),\n                'star_rating': hotel.get('star_rating', None),\n                'similarity_score': float(similarities[idx_num])\n            })\n        return recs\n\n# Cell 3 — Load real Kaggle input files (paths from your message)\nhotels_df = pd.read_csv('/kaggle/input/hotel-master/hotels_master.csv')\nprocessed_data = pd.read_csv('/kaggle/input/preprocessed-data/preprocessed_hotel_data_final_new.csv')\nuser_hotel_interactions = pd.read_csv('/kaggle/input/user-hotel-interactions/user_hotel_interactions.csv')\nuser_profiles = pd.read_csv('/kaggle/input/user-profiles/user_profiles.csv')\n\n# Inspect briefly\nprint(\"hotels_df:\", hotels_df.shape)\nprint(\"processed_data:\", processed_data.shape)\nprint(\"user_hotel_interactions:\", user_hotel_interactions.shape)\nprint(\"user_profiles:\", user_profiles.shape)\n\n# Cell 4 — Initialize content-based recommender with the PREPROCESSED file (better for amenities)\ncb_recommender = ContentBasedRecommender()\n# Use 'processed_data' (it has amenity_ prefixed columns)\ncb_recommender.load_data(processed_data)\n\n# Cell 5 — Train collaborative model (Surprise SVD)\nreader = Reader(rating_scale=(0, 5))\n# ensure rating column exists and is numeric\nuser_hotel_interactions['rating'] = pd.to_numeric(user_hotel_interactions['rating'], errors='coerce').fillna(0)\ndata = Dataset.load_from_df(user_hotel_interactions[['user_id', 'hotel_id', 'rating']], reader)\nalgo = SVD(n_factors=50, random_state=42)\n# You can cross-validate (optional, somewhat slow)\n# cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=True)\ntrainset = data.build_full_trainset()\nalgo.fit(trainset)\n\n# helper function for collaborative recommendations\nhotel_mapping = processed_data[['hotel_id', 'hotel_name']].drop_duplicates()\nall_hotels = processed_data['hotel_id'].unique().tolist()\n\ndef get_top_n_collab(user_id: int, n: int = 5):\n    # candidate hotels: all hotels not rated by user\n    rated_hotels = user_hotel_interactions[user_hotel_interactions['user_id'] == user_id]['hotel_id'].unique().tolist()\n    hotels_to_predict = [h for h in all_hotels if h not in rated_hotels]\n    # make predictions\n    preds = [algo.predict(user_id, h) for h in hotels_to_predict]\n    preds.sort(key=lambda x: x.est, reverse=True)\n    top_preds = preds[:n]\n    df = pd.DataFrame([(int(p.iid), float(p.est)) for p in top_preds], columns=['hotel_id', 'predicted_rating'])\n    df = df.merge(hotel_mapping, on='hotel_id', how='left')\n    return df\n\n# Cell 6 — Ensemble / merging function\ndef ensemble_recommend(user_preferences: Dict, user_id: int = None, top_n: int = 5, weight_cf: float = 0.6, weight_cb: float = 0.4):\n    \"\"\"\n    City is top priority:\n      - If a city is provided and there are no hotels in that city, return a short message telling user to change city.\n      - If city is provided and hotels exist, restrict BOTH content-based and collaborative candidates to that city.\n      - If no city provided, fall back to previous behavior.\n    \"\"\"\n    # Check for city preference and available hotels\n    city_pref = user_preferences.get('city') if isinstance(user_preferences, dict) else None\n\n    if city_pref:\n        # ensure city column exists\n        city_col = 'city' if 'city' in processed_data.columns else ('location' if 'location' in processed_data.columns else None)\n        if city_col is None:\n            # no city info available in processed_data -> fallback behavior\n            allowed_hotel_ids = processed_data['hotel_id'].unique().tolist()\n        else:\n            allowed_hotel_ids = processed_data[processed_data[city_col] == city_pref]['hotel_id'].unique().tolist()\n\n        if len(allowed_hotel_ids) == 0:\n            # No hotels in requested city -> instruct user to change city preference\n            return {\"status\": \"no_city_matches\", \"message\": \"change your preference city\"}\n    else:\n        # no city preference -> all hotels allowed\n        allowed_hotel_ids = processed_data['hotel_id'].unique().tolist()\n\n    # --- Content-based results (filtered to allowed_hotel_ids) ---\n    cb_recs = cb_recommender.recommend(user_preferences, top_n=top_n*2)\n    cb_df = pd.DataFrame(cb_recs)\n    if cb_df.empty:\n        cb_df = pd.DataFrame(columns=['hotel_id', 'similarity_score'])\n    else:\n        # filter to allowed hotels only\n        cb_df = cb_df[cb_df['hotel_id'].isin(allowed_hotel_ids)].copy()\n    cb_df['hotel_id'] = cb_df['hotel_id'].astype(int)\n\n    # Normalize CB similarity\n    if not cb_df.empty and cb_df['similarity_score'].max() > cb_df['similarity_score'].min():\n        cb_df['cb_norm'] = (cb_df['similarity_score'] - cb_df['similarity_score'].min()) / (cb_df['similarity_score'].max() - cb_df['similarity_score'].min() + 1e-9)\n    elif not cb_df.empty:\n        cb_df['cb_norm'] = 1.0  # all equal similarity -> set 1\n    else:\n        cb_df['cb_norm'] = 0.0\n\n    # --- Collaborative results (filtered to allowed_hotel_ids) ---\n    if user_id is not None:\n        cf_df = get_top_n_collab(user_id, n=top_n*5)\n        if not cf_df.empty:\n            cf_df = cf_df[cf_df['hotel_id'].isin(allowed_hotel_ids)].copy()\n            if not cf_df.empty and cf_df['predicted_rating'].max() > cf_df['predicted_rating'].min():\n                cf_df['cf_norm'] = (cf_df['predicted_rating'] - cf_df['predicted_rating'].min()) / (cf_df['predicted_rating'].max() - cf_df['predicted_rating'].min() + 1e-9)\n            elif not cf_df.empty:\n                cf_df['cf_norm'] = 1.0\n            else:\n                cf_df['cf_norm'] = 0.0\n        else:\n            cf_df = pd.DataFrame(columns=['hotel_id', 'predicted_rating', 'cf_norm'])\n    else:\n        cf_df = pd.DataFrame(columns=['hotel_id', 'predicted_rating', 'cf_norm'])\n\n    # If both are empty after filtering, return message\n    if cb_df.empty and cf_df.empty:\n        return {\"status\": \"no_matches_after_filter\", \"message\": \"change your preference city or relax other filters\"}\n\n    # Merge and compute combined score (only on hotel_id)\n    merged = pd.merge(cb_df[['hotel_id','cb_norm']], cf_df[['hotel_id','cf_norm']], on='hotel_id', how='outer').fillna(0)\n    merged['combined_score'] = weight_cf * merged['cf_norm'] + weight_cb * merged['cb_norm']\n    merged = merged.sort_values('combined_score', ascending=False).head(top_n)\n\n    # Enrich with hotel metadata\n    merged = merged.merge(processed_data[['hotel_id','hotel_name','city','price_per_night']], on='hotel_id', how='left').drop_duplicates('hotel_id')\n\n    # Build final response\n    results = []\n    for _, row in merged.iterrows():\n        explanation = []\n        if row.get('cf_norm', 0) > 0:\n            explanation.append(f\"Collaborative score contribution: {row['cf_norm']:.3f}\")\n        if row.get('cb_norm', 0) > 0:\n            explanation.append(f\"Content similarity contribution: {row['cb_norm']:.3f}\")\n        results.append({\n            'hotel_id': int(row['hotel_id']),\n            'hotel_name': row.get('hotel_name', 'Unknown'),\n            'city': row.get('city', ''),\n            'price_per_night': float(row.get('price_per_night')) if not pd.isna(row.get('price_per_night')) else None,\n            'combined_score': float(row['combined_score']),\n            'explanation': \" | \".join(explanation)\n        })\n\n    return results\n\n# Cell 7 — Wrap as LangChain Tools\ndef cb_tool_func(query_json: str) -> str:\n    \"\"\"\n    Input: JSON string with user preferences (same structure as user_profiles row).\n    Output: JSON string with top-5 content-based recommendations.\n    \"\"\"\n    prefs = json.loads(query_json)\n    recs = cb_recommender.recommend(prefs, top_n=5)\n    return json.dumps(recs, default=str)\n\ndef cf_tool_func(query_json: str) -> str:\n    \"\"\"\n    Input: JSON string with {'user_id': <int>, 'n': 5}\n    Output: JSON string with top-n collaborative recommendations\n    \"\"\"\n    payload = json.loads(query_json)\n    uid = int(payload.get('user_id'))\n    n = int(payload.get('n', 5))\n    df = get_top_n_collab(uid, n=n)\n    return df.to_json(orient='records')\n\ndef ensemble_tool_func(query_json: str) -> str:\n    \"\"\"\n    Input JSON: {'user_id': <int or null>, 'user_preferences': {...}, 'top_n': 5}\n    Output: JSON array with final recommendations\n    \"\"\"\n    payload = json.loads(query_json)\n    uid = payload.get('user_id')  # can be null\n    user_prefs = payload.get('user_preferences', {})\n    top_n = int(payload.get('top_n', 5))\n    results = ensemble_recommend(user_prefs, user_id=uid, top_n=top_n)\n    return json.dumps(results, default=str)\n\n# Create LangChain Tool objects\ncb_tool = Tool(\n    name=\"content_based_recommender\",\n    func=cb_tool_func,\n    description=\"Given a JSON-encoded user preferences object, returns top content-based hotel recommendations.\"\n)\n\ncf_tool = Tool(\n    name=\"collaborative_recommender\",\n    func=cf_tool_func,\n    description=\"Given a JSON string with user_id and n, returns top-n collaborative recommendations.\"\n)\n\nensemble_tool = Tool(\n    name=\"ensemble_recommender\",\n    func=ensemble_tool_func,\n    description=\"Given a JSON payload containing user_id (optional) and user_preferences, returns merged recommendations.\"\n)\n\n# Cell 8 — Build LangChain Agent (requires GEMINI_API_KEY)\nGEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', None)\nif GEMINI_API_KEY is None:\n    print(\"GEMINI_API_KEY not set in environment. To use the LangChain agent, set GEMINI_API_KEY in Kaggle secrets.\")\nelse:\n    from langchain_google_genai import ChatGoogleGenerativeAI\n    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, google_api_key=GEMINI_API_KEY)\n\n    tools = [cb_tool, cf_tool, ensemble_tool]\n    # initialize a zero-shot agent (tool-using)\n    agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n\n    # Example prompt you can give to the agent (string). The agent will choose tools as needed.\n    example_query = (\n        \"Recommend 5 hotels for user with user_id=1. \"\n        \"The user preferences: city='Bangalore', preferred_amenities=['pool','gym'], budget_min_inr=1000, budget_max_inr=10000, min_star_rating=4. \"\n        \"Please use collaborative info where possible and combine with content-based, provide short explanations.\"\n    )\n    # The agent expects natural language; we embed a JSON payload where needed. Example:\n    agent_input = (\n        \"Use ensemble_recommender tool with this JSON payload: \"\n        + json.dumps({\n            \"user_id\": 1,\n            \"user_preferences\": {\n                \"city\": \"Bangalore\",\n                \"preferred_amenities\": [\"pool\", \"gym\"],\n                \"budget_min_inr\": 1000,\n                \"budget_max_inr\": 10000,\n                \"min_star_rating\": 4\n            },\n            \"top_n\": 5\n        })\n    )\n    # Run agent (if GEMINI_API_KEY present)\n    resp = agent.run(agent_input)\n    print(resp)\n\n# Paste this entire block to replace your previous generate_llm_explanations + deterministic_explanation\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import HumanMessage\nfrom google.api_core.exceptions import ResourceExhausted, NotFound\nimport traceback\n\ndef deterministic_explanation(r, user_prefs):\n    \"\"\"Simple rule-based explanation when LLM is unavailable.\"\"\"\n    parts = []\n    # city match\n    if user_prefs.get('city') and r.get('city') == user_prefs.get('city'):\n        parts.append(f\"Located in your chosen city {r.get('city')}.\")\n    # price\n    price = r.get('price_per_night')\n    if price is not None and 'budget_min_inr' in user_prefs and 'budget_max_inr' in user_prefs:\n        try:\n            if user_prefs['budget_min_inr'] <= price <= user_prefs['budget_max_inr']:\n                parts.append(f\"Priced within your budget at ₹{int(price):,} per night.\")\n            elif price < user_prefs['budget_min_inr']:\n                parts.append(f\"Below your budget at ₹{int(price):,} per night.\")\n            else:\n                parts.append(f\"Higher than your stated max budget at ₹{int(price):,}.\")\n        except Exception:\n            pass\n    # star rating\n    if user_prefs.get('min_star_rating') and r.get('star_rating') is not None:\n        try:\n            if float(r.get('star_rating')) >= float(user_prefs['min_star_rating']):\n                parts.append(f\"Meets your star rating requirement ({r.get('star_rating')}★).\")\n        except Exception:\n            pass\n    # scores\n    if r.get('combined_score') is not None:\n        parts.append(f\"Combined score {r.get('combined_score'):.2f}.\")\n    # fallback\n    if not parts:\n        parts = [\"Recommended based on collaborative signals and content similarity.\"]\n    explanation = \" \".join(parts)\n    # Keep it brief (one or two sentences)\n    if len(explanation) > 240:\n        explanation = explanation[:237] + \"...\"\n    return explanation\n\ndef _extract_text_from_llm_response(resp):\n    \"\"\"\n    Normalize a variety of possible LangChain/LLM response shapes to extract text:\n    - If resp is a string -> return it\n    - If resp has attribute 'content' -> return resp.content\n    - If resp has attribute 'generations' -> grab first generation text\n    - If resp is a dict/list -> try to search common fields\n    \"\"\"\n    try:\n        if resp is None:\n            return \"\"\n        # plain string\n        if isinstance(resp, str):\n            return resp\n        # object with content attribute (ChatMessage-like)\n        if hasattr(resp, \"content\"):\n            return str(resp.content)\n        # LLMResult in some LangChain versions: resp.generations -> list[list[Generation]]\n        if hasattr(resp, \"generations\"):\n            gens = resp.generations\n            # gens might be list of lists\n            if isinstance(gens, list) and len(gens) > 0:\n                first = gens[0]\n                # first can be list or Generation\n                if isinstance(first, list) and len(first) > 0:\n                    g0 = first[0]\n                    # Generation has .text or .generation\n                    if hasattr(g0, \"text\"):\n                        return str(g0.text)\n                    elif hasattr(g0, \"generation\"):\n                        return str(g0.generation)\n                else:\n                    g0 = first\n                    if hasattr(g0, \"text\"):\n                        return str(g0.text)\n                    elif hasattr(g0, \"generation\"):\n                        return str(g0.generation)\n        # dict-like\n        if isinstance(resp, dict):\n            # try common keys\n            for k in (\"text\", \"output\", \"content\", \"response\"):\n                if k in resp and resp[k]:\n                    return str(resp[k])\n            # nested possibilities\n            if \"choices\" in resp and isinstance(resp[\"choices\"], list) and len(resp[\"choices\"]) > 0:\n                ch = resp[\"choices\"][0]\n                if isinstance(ch, dict):\n                    for k in (\"text\", \"message\", \"content\"):\n                        if k in ch:\n                            return str(ch[k])\n        # list-like: join texts\n        if isinstance(resp, list):\n            texts = []\n            for item in resp:\n                try:\n                    texts.append(_extract_text_from_llm_response(item))\n                except Exception:\n                    continue\n            return \" \".join([t for t in texts if t])\n        # lastly, fallback to string conversion\n        return str(resp)\n    except Exception:\n        return str(resp)\n\ndef generate_llm_explanations(recs, user_prefs, model_name=\"gemini-2.0-flash\", max_tokens=150):\n    \"\"\"\n    Generate LLM explanations for each recommendation in `recs`.\n    - recs: list of dicts from ensemble_recommend (each must contain 'hotel_id', 'hotel_name', etc.)\n    - user_prefs: dict used to compute recommendations\n    - model_name: exact Gemini model name (from your model listing). Default uses gemini-2.0-flash.\n    Returns: new list with 'llm_explanation' field added for each rec (falls back deterministically on errors).\n    \"\"\"\n    gemini_key = os.environ.get(\"GEMINI_API_KEY\")\n    if not gemini_key:\n        # No key: attach deterministic explanations and return\n        for r in recs:\n            r['llm_explanation'] = deterministic_explanation(r, user_prefs)\n        return recs\n\n    # instantiate LLM\n    try:\n        llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.0, max_output_tokens=max_tokens, google_api_key=gemini_key)\n    except Exception as e:\n        # if initialization fails, fallback deterministically\n        print(\"LLM init error - falling back to deterministic explanations:\", e)\n        for r in recs:\n            r['llm_explanation'] = deterministic_explanation(r, user_prefs)\n        return recs\n\n    enriched = []\n    for r in recs:\n        try:\n            # Locate hotel metadata row if available\n            hid = None\n            try:\n                hid = int(r.get('hotel_id'))\n            except Exception:\n                hid = None\n\n            hotel_row = processed_data[processed_data['hotel_id'] == hid] if hid is not None else pd.DataFrame()\n\n            # Build facts (compact)\n            facts = {}\n            if not hotel_row.empty:\n                hr = hotel_row.iloc[0]\n                facts['hotel_name'] = hr.get('hotel_name') if 'hotel_name' in hr.index else hr.get('name', r.get('hotel_name'))\n                facts['city'] = hr.get('city', hr.get('location', r.get('city')))\n                # attempt to get reasonable price\n                for pc in ['price_per_night', 'price_per_night_inr', 'price_per_night_inr']:\n                    if pc in hr.index and not pd.isna(hr.get(pc)):\n                        try:\n                            facts['price'] = int(hr.get(pc))\n                            break\n                        except Exception:\n                            pass\n                facts['star_rating'] = hr.get('star_rating') if 'star_rating' in hr.index else hr.get('star_rating_clean', r.get('star_rating'))\n                # amenities\n                amenity_cols = [c for c in processed_data.columns if str(c).startswith('amenity_')]\n                present_amenities = []\n                for ac in amenity_cols:\n                    try:\n                        if int(hr.get(ac, 0)) == 1:\n                            present_amenities.append(ac.replace('amenity_','').replace('_',' '))\n                    except Exception:\n                        pass\n                facts['amenities'] = present_amenities[:6]\n            else:\n                facts['hotel_name'] = r.get('hotel_name')\n                facts['city'] = r.get('city')\n                facts['price'] = r.get('price_per_night')\n                facts['star_rating'] = r.get('star_rating')\n                facts['amenities'] = []\n\n            # ensemble scores\n            cb_score = r.get('similarity_score') or r.get('cb_norm') or None\n            cf_score = r.get('predicted_rating') or r.get('cf_norm') or None\n            combined = r.get('combined_score')\n\n            # Build prompt\n            prompt_lines = [\n                \"You are a helpful recommender-system assistant. Produce a concise (2-3 sentences) explanation — no lists — explaining WHY this hotel is recommended to the user. Mention the user's key preferences and any tradeoffs (price, rating, amenities).\",\n                \"\",\n                f\"User preferences: {json.dumps(user_prefs)}\",\n                \"\",\n                \"Hotel facts:\",\n                f\"  name: {facts.get('hotel_name')}\",\n                f\"  city: {facts.get('city')}\",\n            ]\n            if facts.get('price') is not None:\n                prompt_lines.append(f\"  price_per_night: ₹{facts.get('price'):,}\")\n            if facts.get('star_rating') is not None:\n                prompt_lines.append(f\"  star_rating: {facts.get('star_rating')}\")\n            if facts.get('amenities'):\n                prompt_lines.append(f\"  amenities (sample): {', '.join(facts.get('amenities'))}\")\n            if cb_score is not None:\n                prompt_lines.append(f\"  content_similarity_score: {cb_score}\")\n            if cf_score is not None:\n                prompt_lines.append(f\"  collaborative_score: {cf_score}\")\n            if combined is not None:\n                try:\n                    prompt_lines.append(f\"  combined_score: {combined:.3f}\")\n                except Exception:\n                    pass\n\n            prompt_lines.append(\"\")\n            prompt_lines.append(\"Write the explanation now:\")\n\n            prompt = \"\\n\".join(prompt_lines)\n\n            # call Gemini correctly using a HumanMessage and invoke\n            human_msg = HumanMessage(content=prompt)\n            resp = llm.invoke([human_msg])\n\n            text = _extract_text_from_llm_response(resp)\n            text = text.strip().replace(\"\\n\", \" \")\n            # safety: if LLM outputs empty, fallback to deterministic\n            if not text:\n                text = deterministic_explanation(r, user_prefs)\n\n            r['llm_explanation'] = text\n            enriched.append(r)\n\n        except ResourceExhausted as e:\n            # quota problem -> fallback deterministic\n            r['llm_explanation'] = deterministic_explanation(r, user_prefs)\n            enriched.append(r)\n        except NotFound as e:\n            # model not found or method not supported -> fallback deterministic\n            r['llm_explanation'] = deterministic_explanation(r, user_prefs)\n            enriched.append(r)\n        except Exception as e:\n            # Any other error: deterministic fallback + debug print\n            r['llm_explanation'] = deterministic_explanation(r, user_prefs)\n            enriched.append(r)\n            print(f\"LLM explain error for hotel_id {r.get('hotel_id')}: {e}\")\n            traceback.print_exc()\n\n    return enriched\n\n# Example usage (uncomment to run):\nexample_user_prefs = {\n     \"city\": \"Bangalore\",\n     \"preferred_amenities\": [\"pool\", \"gym\"],\n     \"budget_min_inr\": 1000,\n     \"budget_max_inr\": 10000,\n     \"min_star_rating\": 4\n }\nensemble_results = ensemble_recommend(example_user_prefs, user_id=1, top_n=5)\nenriched_results = generate_llm_explanations(ensemble_results, example_user_prefs, model_name=\"gemini-1.5-pro-002\", max_tokens=120)\nprint(json.dumps(enriched_results, indent=2, ensure_ascii=False))\n\n\n\n# Cell 9 — Example direct calls without LLM (recommended for testing quickly)\n# Get content-based recommendations for a sample user profile (from user_profiles)\nsample_user = user_profiles.iloc[0].to_dict()\n# user_profiles has preferred_amenities as string e.g. '[\"pool\", \"family_rooms\", \"parking\"]'\nprint(\"\\nContent-based recs (direct):\")\nprint(cb_tool_func(json.dumps({\n    \"city\": sample_user.get('home_city', sample_user.get('city', None)),\n    \"preferred_amenities\": sample_user.get('preferred_amenities'),\n    \"budget_min_inr\": int(sample_user.get('budget_min_inr', 0)),\n    \"budget_max_inr\": int(sample_user.get('budget_max_inr', 999999)),\n    \"min_star_rating\": int(sample_user.get('min_star_rating', 0)) if sample_user.get('min_star_rating') else None\n})))\n\nprint(\"\\nCollaborative recs (direct) for user_id=1:\")\nprint(cf_tool_func(json.dumps({\"user_id\": 1, \"n\": 5})))\n\nprint(\"\\nEnsemble recs (direct):\")\nprint(ensemble_tool_func(json.dumps({\n    \"user_id\": 1,\n    \"user_preferences\": {\n        \"city\": \"Bangalore\",\n        \"preferred_amenities\": [\"pool\", \"gym\"],\n        \"budget_min_inr\": 1000,\n        \"budget_max_inr\": 10000,\n        \"min_star_rating\": 4\n    },\n    \"top_n\": 5\n})))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:14:15.358075Z","iopub.execute_input":"2025-09-08T09:14:15.358350Z","iopub.status.idle":"2025-09-08T09:14:28.944310Z","shell.execute_reply.started":"2025-09-08T09:14:15.358329Z","shell.execute_reply":"2025-09-08T09:14:28.943665Z"}},"outputs":[{"name":"stdout","text":"hotels_df: (400, 27)\nprocessed_data: (4632, 39)\nuser_hotel_interactions: (1288, 11)\nuser_profiles: (300, 16)\n\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3503859650.py:372: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n  agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n/tmp/ipykernel_36/3503859650.py:396: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  resp = agent.run(agent_input)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32;1m\u001b[1;3mI should use the ensemble_recommender tool to get the merged hotel recommendations based on the provided user ID and preferences.\nAction: ensemble_recommender\nAction Input: {\"user_id\": 1, \"user_preferences\": {\"city\": \"Bangalore\", \"preferred_amenities\": [\"pool\", \"gym\"], \"budget_min_inr\": 1000, \"budget_max_inr\": 10000, \"min_star_rating\": 4}, \"top_n\": 5}\u001b[0m\nObservation: \u001b[38;5;200m\u001b[1;3m[{\"hotel_id\": 298, \"hotel_name\": \"Fairfield By Marriott Bengaluru Rajajinagar\", \"city\": \"Bangalore\", \"price_per_night\": 5400.0, \"combined_score\": 0.6027283963837166, \"explanation\": \"Collaborative score contribution: 1.000 | Content similarity contribution: 0.007\"}, {\"hotel_id\": 1338, \"hotel_name\": \"The Leela Bhartiya City\", \"city\": \"Bangalore\", \"price_per_night\": 4300.0, \"combined_score\": 0.3999999971671504, \"explanation\": \"Content similarity contribution: 1.000\"}, {\"hotel_id\": 1607, \"hotel_name\": \"Radisson Bengaluru City Center\", \"city\": \"Bangalore\", \"price_per_night\": 7500.0, \"combined_score\": 0.01699126848760607, \"explanation\": \"Content similarity contribution: 0.042\"}, {\"hotel_id\": 732, \"hotel_name\": \"Greenpark Bengaluru\", \"city\": \"Bangalore\", \"price_per_night\": 6345.0, \"combined_score\": 0.009159528869237762, \"explanation\": \"Content similarity contribution: 0.023\"}, {\"hotel_id\": 678, \"hotel_name\": \"Royal Orchid Central Bangalore\", \"city\": \"Bangalore\", \"price_per_night\": 5823.0, \"combined_score\": 0.005609662464350597, \"explanation\": \"Content similarity contribution: 0.014\"}]\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mI have successfully used the ensemble_recommender tool and obtained the top 5 hotel recommendations for the given user preferences.\nFinal Answer: The top 5 hotel recommendations are: Fairfield By Marriott Bengaluru Rajajinagar (hotel_id: 298), The Leela Bhartiya City (hotel_id: 1338), Radisson Bengaluru City Center (hotel_id: 1607), Greenpark Bengaluru (hotel_id: 732), and Royal Orchid Central Bangalore (hotel_id: 678).\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nThe top 5 hotel recommendations are: Fairfield By Marriott Bengaluru Rajajinagar (hotel_id: 298), The Leela Bhartiya City (hotel_id: 1338), Radisson Bengaluru City Center (hotel_id: 1607), Greenpark Bengaluru (hotel_id: 732), and Royal Orchid Central Bangalore (hotel_id: 678).\n[\n  {\n    \"hotel_id\": 298,\n    \"hotel_name\": \"Fairfield By Marriott Bengaluru Rajajinagar\",\n    \"city\": \"Bangalore\",\n    \"price_per_night\": 5400.0,\n    \"combined_score\": 0.6027283963837166,\n    \"explanation\": \"Collaborative score contribution: 1.000 | Content similarity contribution: 0.007\",\n    \"llm_explanation\": \"Located in your chosen city Bangalore. Priced within your budget at ₹5,400 per night. Combined score 0.60.\"\n  },\n  {\n    \"hotel_id\": 1338,\n    \"hotel_name\": \"The Leela Bhartiya City\",\n    \"city\": \"Bangalore\",\n    \"price_per_night\": 4300.0,\n    \"combined_score\": 0.3999999971671504,\n    \"explanation\": \"Content similarity contribution: 1.000\",\n    \"llm_explanation\": \"Located in your chosen city Bangalore. Priced within your budget at ₹4,300 per night. Combined score 0.40.\"\n  },\n  {\n    \"hotel_id\": 1607,\n    \"hotel_name\": \"Radisson Bengaluru City Center\",\n    \"city\": \"Bangalore\",\n    \"price_per_night\": 7500.0,\n    \"combined_score\": 0.01699126848760607,\n    \"explanation\": \"Content similarity contribution: 0.042\",\n    \"llm_explanation\": \"Located in your chosen city Bangalore. Priced within your budget at ₹7,500 per night. Combined score 0.02.\"\n  },\n  {\n    \"hotel_id\": 732,\n    \"hotel_name\": \"Greenpark Bengaluru\",\n    \"city\": \"Bangalore\",\n    \"price_per_night\": 6345.0,\n    \"combined_score\": 0.009159528869237762,\n    \"explanation\": \"Content similarity contribution: 0.023\",\n    \"llm_explanation\": \"Located in your chosen city Bangalore. Priced within your budget at ₹6,345 per night. Combined score 0.01.\"\n  },\n  {\n    \"hotel_id\": 678,\n    \"hotel_name\": \"Royal Orchid Central Bangalore\",\n    \"city\": \"Bangalore\",\n    \"price_per_night\": 5823.0,\n    \"combined_score\": 0.005609662464350597,\n    \"explanation\": \"Content similarity contribution: 0.014\",\n    \"llm_explanation\": \"Located in your chosen city Bangalore. Priced within your budget at ₹5,823 per night. Combined score 0.01.\"\n  }\n]\n\nContent-based recs (direct):\n[]\n\nCollaborative recs (direct) for user_id=1:\n[{\"hotel_id\":313,\"predicted_rating\":5.0,\"hotel_name\":\"Anjuna 4BR Luxury Villa Aman w\\/private pool\"},{\"hotel_id\":107,\"predicted_rating\":4.9573608684,\"hotel_name\":\"BISWAS HOTEL\"},{\"hotel_id\":195,\"predicted_rating\":4.9501852959,\"hotel_name\":\"Dover Inn By BookMeriHotel\"},{\"hotel_id\":353,\"predicted_rating\":4.894822565,\"hotel_name\":\"BSRA Cross B\"},{\"hotel_id\":311,\"predicted_rating\":4.8795375842,\"hotel_name\":\"Cancio's House\"}]\n\nEnsemble recs (direct):\n[{\"hotel_id\": 298, \"hotel_name\": \"Fairfield By Marriott Bengaluru Rajajinagar\", \"city\": \"Bangalore\", \"price_per_night\": 5400.0, \"combined_score\": 0.6027283963837166, \"explanation\": \"Collaborative score contribution: 1.000 | Content similarity contribution: 0.007\"}, {\"hotel_id\": 1338, \"hotel_name\": \"The Leela Bhartiya City\", \"city\": \"Bangalore\", \"price_per_night\": 4300.0, \"combined_score\": 0.3999999971671504, \"explanation\": \"Content similarity contribution: 1.000\"}, {\"hotel_id\": 1607, \"hotel_name\": \"Radisson Bengaluru City Center\", \"city\": \"Bangalore\", \"price_per_night\": 7500.0, \"combined_score\": 0.01699126848760607, \"explanation\": \"Content similarity contribution: 0.042\"}, {\"hotel_id\": 732, \"hotel_name\": \"Greenpark Bengaluru\", \"city\": \"Bangalore\", \"price_per_night\": 6345.0, \"combined_score\": 0.009159528869237762, \"explanation\": \"Content similarity contribution: 0.023\"}, {\"hotel_id\": 678, \"hotel_name\": \"Royal Orchid Central Bangalore\", \"city\": \"Bangalore\", \"price_per_night\": 5823.0, \"combined_score\": 0.005609662464350597, \"explanation\": \"Content similarity contribution: 0.014\"}]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import Dataset, Reader, SVD\nfrom surprise.model_selection import cross_validate\nfrom langchain.tools import Tool\nfrom langchain.agents import initialize_agent, AgentType\n# Note: we don't import OpenAI here when using Gemini; keep for compatibility if needed\nfrom langchain.llms import OpenAI\nfrom langchain import LLMChain, PromptTemplate\nfrom typing import List, Dict, Tuple\n\n# -------------------------\n# Content-based recommender\n# -------------------------\nclass ContentBasedRecommender:\n    def __init__(self):\n        self.hotels_df = None\n        self.feature_weights = {\n            'amenities': 0.35,\n            'location': 0.25,\n            'price': 0.20,\n            'star_rating': 0.15,\n            'property_type': 0.05\n        }\n        self.amenity_features = [\n            'amenity_free_wifi', 'amenity_air_conditioning', 'amenity_parking', 'amenity_room_service',\n            'amenity_24_7_front_desk', 'amenity_restaurant', 'amenity_gym', 'amenity_pool', 'amenity_spa',\n            'amenity_business_center', 'amenity_conference_hall', 'amenity_airport_shuttle',\n            'amenity_meeting_rooms', 'amenity_vegetarian_restaurant'\n        ]\n        self.scaler = MinMaxScaler()\n\n    def load_data(self, hotels_df: pd.DataFrame):\n        self.hotels_df = hotels_df.copy()\n        # ensure amenity columns present and integer\n        for amenity in self.amenity_features:\n            if amenity in self.hotels_df.columns:\n                self.hotels_df[amenity] = self.hotels_df[amenity].fillna(0).astype(int)\n            else:\n                self.hotels_df[amenity] = 0\n\n        # city/location dummies\n        city_col = 'city' if 'city' in self.hotels_df.columns else ('location' if 'location' in self.hotels_df.columns else None)\n        if city_col is not None:\n            location_dummies = pd.get_dummies(self.hotels_df[city_col].fillna('Unknown'), prefix='city')\n            self.hotels_df = pd.concat([self.hotels_df, location_dummies], axis=1)\n        else:\n            location_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        # price normalization\n        price_col = 'price_per_night' if 'price_per_night' in self.hotels_df.columns else ('price_per_night_inr' if 'price_per_night_inr' in self.hotels_df.columns else 'price_per_night_inr')\n        rating_col = 'star_rating' if 'star_rating' in self.hotels_df.columns else ('star_rating_clean' if 'star_rating_clean' in self.hotels_df.columns else None)\n\n        if price_col in self.hotels_df.columns:\n            self.hotels_df[price_col] = pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(self.hotels_df[price_col].median())\n            self.hotels_df['price_normalized'] = self.scaler.fit_transform(self.hotels_df[[price_col]])\n        else:\n            self.hotels_df['price_normalized'] = 0.0\n\n        if rating_col:\n            self.hotels_df[rating_col] = pd.to_numeric(self.hotels_df[rating_col], errors='coerce').fillna(self.hotels_df[rating_col].median())\n            self.hotels_df['rating_normalized'] = self.scaler.fit_transform(self.hotels_df[[rating_col]])\n        else:\n            self.hotels_df['rating_normalized'] = 0.0\n\n        # property type dummies\n        property_col = 'hotel_type' if 'hotel_type' in self.hotels_df.columns else ('property_type' if 'property_type' in self.hotels_df.columns else None)\n        if property_col:\n            property_dummies = pd.get_dummies(self.hotels_df[property_col].fillna('Unknown'), prefix='property')\n            self.hotels_df = pd.concat([self.hotels_df, property_dummies], axis=1)\n        else:\n            property_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        self.feature_columns = (\n            self.amenity_features +\n            list(location_dummies.columns) +\n            ['price_normalized', 'rating_normalized'] +\n            list(property_dummies.columns)\n        )\n\n        for col in self.feature_columns:\n            if col not in self.hotels_df.columns:\n                self.hotels_df[col] = 0\n\n        self.hotels_df['feature_vector'] = self.hotels_df[self.feature_columns].values.tolist()\n        return self\n\n    def _create_user_profile(self, user_preferences: Dict):\n        user_vector = np.zeros(len(self.feature_columns))\n        feature_idx_map = {feature: idx for idx, feature in enumerate(self.feature_columns)}\n\n        # city\n        if 'city' in user_preferences:\n            city_feature = f\"city_{user_preferences['city']}\"\n            if city_feature in feature_idx_map:\n                user_vector[feature_idx_map[city_feature]] = 1.0\n\n        # preferred amenities\n        if 'preferred_amenities' in user_preferences and user_preferences['preferred_amenities']:\n            pref = user_preferences['preferred_amenities']\n            if isinstance(pref, str):\n                try:\n                    preferred_amenities = json.loads(pref)\n                except Exception:\n                    preferred_amenities = [pref]\n            else:\n                preferred_amenities = pref\n            for amenity in preferred_amenities:\n                col_name = amenity if amenity.startswith('amenity_') else f'amenity_{amenity}'\n                if col_name in feature_idx_map:\n                    user_vector[feature_idx_map[col_name]] = 1.0\n\n        # budget influence\n        if 'budget_min_inr' in user_preferences and 'budget_max_inr' in user_preferences:\n            price_norm_idx = feature_idx_map.get('price_normalized')\n            if price_norm_idx is not None:\n                user_vector[price_norm_idx] = 1.0\n\n        return user_vector\n\n    def calculate_similarity(self, user_preferences: Dict, top_n: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n        if self.hotels_df is None:\n            raise ValueError(\"Load data first\")\n        user_vector = self._create_user_profile(user_preferences)\n        hotel_vectors = np.array(self.hotels_df['feature_vector'].tolist())\n        sims = cosine_similarity([user_vector], hotel_vectors)[0]\n        filtered_indices = self._apply_filters(user_preferences)\n        filtered_sims = sims[filtered_indices]\n        top_indices = filtered_indices[np.argsort(filtered_sims)[-top_n:][::-1]]\n        return top_indices, sims[top_indices]\n\n    def _apply_filters(self, user_preferences: Dict):\n        mask = pd.Series(True, index=self.hotels_df.index)\n        if 'city' in user_preferences:\n            city_col = 'city' if 'city' in self.hotels_df.columns else 'location'\n            if city_col:\n                mask &= (self.hotels_df[city_col] == user_preferences['city'])\n        if 'budget_min_inr' in user_preferences and 'budget_max_inr' in user_preferences:\n            price_col = 'price_per_night' if 'price_per_night' in self.hotels_df.columns else ('price_per_night_inr' if 'price_per_night_inr' in self.hotels_df.columns else None)\n            if price_col:\n                mask &= (pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(0) >= user_preferences['budget_min_inr']) & \\\n                        (pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(0) <= user_preferences['budget_max_inr'])\n        if 'min_star_rating' in user_preferences and 'star_rating' in self.hotels_df.columns:\n            mask &= (pd.to_numeric(self.hotels_df['star_rating'], errors='coerce').fillna(0) >= user_preferences['min_star_rating'])\n        return mask[mask].index\n\n    def recommend(self, user_preferences: Dict, top_n: int = 5):\n        top_indices, similarities = self.calculate_similarity(user_preferences, top_n * 2)\n        recs = []\n        for idx_num, hotel_idx in enumerate(top_indices[:top_n]):\n            hotel = self.hotels_df.iloc[hotel_idx]\n            recs.append({\n                'hotel_id': int(hotel.get('hotel_id', hotel.get('hotel_id'))),\n                'hotel_name': hotel.get('hotel_name', hotel.get('hotel_name', hotel.get('name', 'Unknown'))),\n                'city': hotel.get('city', hotel.get('location', 'Unknown')),\n                'price_per_night': float(hotel.get('price_per_night', hotel.get('price_per_night_inr', 0))),\n                'star_rating': hotel.get('star_rating', None),\n                'similarity_score': float(similarities[idx_num])\n            })\n        return recs\n\n# -------------------------\n# Load data\n# -------------------------\nhotels_df = pd.read_csv('/kaggle/input/hotel-master/hotels_master.csv')\nprocessed_data = pd.read_csv('/kaggle/input/preprocessed-data/preprocessed_hotel_data_final_new.csv')\nuser_hotel_interactions = pd.read_csv('/kaggle/input/user-hotel-interactions/user_hotel_interactions.csv')\nuser_profiles = pd.read_csv('/kaggle/input/user-profiles/user_profiles.csv')\n\nprint(\"hotels_df:\", hotels_df.shape)\nprint(\"processed_data:\", processed_data.shape)\nprint(\"user_hotel_interactions:\", user_hotel_interactions.shape)\nprint(\"user_profiles:\", user_profiles.shape)\n\n# initialize CB\ncb_recommender = ContentBasedRecommender()\ncb_recommender.load_data(processed_data)\n\n# -------------------------\n# Collaborative (Surprise SVD)\n# -------------------------\nreader = Reader(rating_scale=(0, 5))\nuser_hotel_interactions['rating'] = pd.to_numeric(user_hotel_interactions['rating'], errors='coerce').fillna(0)\ndata = Dataset.load_from_df(user_hotel_interactions[['user_id', 'hotel_id', 'rating']], reader)\nalgo = SVD(n_factors=50, random_state=42)\ntrainset = data.build_full_trainset()\nalgo.fit(trainset)\n\nhotel_mapping = processed_data[['hotel_id', 'hotel_name']].drop_duplicates()\nall_hotels = processed_data['hotel_id'].unique().tolist()\n\ndef get_top_n_collab(user_id: int, n: int = 5):\n    rated_hotels = user_hotel_interactions[user_hotel_interactions['user_id'] == user_id]['hotel_id'].unique().tolist()\n    hotels_to_predict = [h for h in all_hotels if h not in rated_hotels]\n    preds = [algo.predict(user_id, h) for h in hotels_to_predict]\n    preds.sort(key=lambda x: x.est, reverse=True)\n    top_preds = preds[:n]\n    df = pd.DataFrame([(int(p.iid), float(p.est)) for p in top_preds], columns=['hotel_id', 'predicted_rating'])\n    df = df.merge(hotel_mapping, on='hotel_id', how='left')\n    return df\n\n# -------------------------\n# Ensemble recommender (city-first)\n# -------------------------\ndef ensemble_recommend(user_preferences: Dict, user_id: int = None, top_n: int = 5, weight_cf: float = 0.6, weight_cb: float = 0.4):\n    # ensure user_preferences is dict\n    user_preferences = user_preferences or {}\n    city_pref = user_preferences.get('city')\n\n    # determine city column\n    city_col = 'city' if 'city' in processed_data.columns else ('location' if 'location' in processed_data.columns else None)\n    if city_pref:\n        if city_col is None:\n            allowed_hotel_ids = processed_data['hotel_id'].unique().tolist()\n        else:\n            allowed_hotel_ids = processed_data[processed_data[city_col] == city_pref]['hotel_id'].unique().tolist()\n        if len(allowed_hotel_ids) == 0:\n            return {\"status\": \"no_city_matches\", \"message\": \"change your preference city\"}\n    else:\n        allowed_hotel_ids = processed_data['hotel_id'].unique().tolist()\n\n    # content-based\n    cb_recs = cb_recommender.recommend(user_preferences, top_n=top_n*2)\n    cb_df = pd.DataFrame(cb_recs)\n    if cb_df.empty:\n        cb_df = pd.DataFrame(columns=['hotel_id', 'similarity_score'])\n    else:\n        cb_df = cb_df[cb_df['hotel_id'].isin(allowed_hotel_ids)].copy()\n    if 'hotel_id' in cb_df.columns:\n        cb_df['hotel_id'] = cb_df['hotel_id'].astype(int)\n\n    if not cb_df.empty and cb_df['similarity_score'].max() > cb_df['similarity_score'].min():\n        cb_df['cb_norm'] = (cb_df['similarity_score'] - cb_df['similarity_score'].min()) / (cb_df['similarity_score'].max() - cb_df['similarity_score'].min() + 1e-9)\n    elif not cb_df.empty:\n        cb_df['cb_norm'] = 1.0\n    else:\n        cb_df['cb_norm'] = 0.0\n\n    # collaborative\n    if user_id is not None:\n        cf_df = get_top_n_collab(user_id, n=top_n*5)\n        if not cf_df.empty:\n            cf_df = cf_df[cf_df['hotel_id'].isin(allowed_hotel_ids)].copy()\n            if not cf_df.empty and cf_df['predicted_rating'].max() > cf_df['predicted_rating'].min():\n                cf_df['cf_norm'] = (cf_df['predicted_rating'] - cf_df['predicted_rating'].min()) / (cf_df['predicted_rating'].max() - cf_df['predicted_rating'].min() + 1e-9)\n            elif not cf_df.empty:\n                cf_df['cf_norm'] = 1.0\n            else:\n                cf_df['cf_norm'] = 0.0\n        else:\n            cf_df = pd.DataFrame(columns=['hotel_id', 'predicted_rating', 'cf_norm'])\n    else:\n        cf_df = pd.DataFrame(columns=['hotel_id', 'predicted_rating', 'cf_norm'])\n\n    if cb_df.empty and cf_df.empty:\n        return {\"status\": \"no_matches_after_filter\", \"message\": \"change your preference city or relax other filters\"}\n\n    merged = pd.merge(cb_df[['hotel_id','cb_norm']], cf_df[['hotel_id','cf_norm']], on='hotel_id', how='outer').fillna(0)\n    merged['combined_score'] = weight_cf * merged['cf_norm'] + weight_cb * merged['cb_norm']\n    merged = merged.sort_values('combined_score', ascending=False).head(top_n)\n    merged = merged.merge(processed_data[['hotel_id','hotel_name','city','price_per_night','star_rating']], on='hotel_id', how='left').drop_duplicates('hotel_id')\n\n    results = []\n    for _, row in merged.iterrows():\n        explanation = []\n        if row.get('cf_norm', 0) > 0:\n            explanation.append(f\"Collaborative score contribution: {row['cf_norm']:.3f}\")\n        if row.get('cb_norm', 0) > 0:\n            explanation.append(f\"Content similarity contribution: {row['cb_norm']:.3f}\")\n        results.append({\n            'hotel_id': int(row['hotel_id']),\n            'hotel_name': row.get('hotel_name', 'Unknown'),\n            'city': row.get('city', ''),\n            'price_per_night': float(row.get('price_per_night')) if not pd.isna(row.get('price_per_night')) else None,\n            'star_rating': row.get('star_rating', None),\n            'combined_score': float(row['combined_score']),\n            'explanation': \" | \".join(explanation)\n        })\n    return results\n\n# -------------------------\n# LangChain Tool wrappers\n# -------------------------\ndef cb_tool_func(query_json: str) -> str:\n    prefs = json.loads(query_json)\n    recs = cb_recommender.recommend(prefs, top_n=5)\n    return json.dumps(recs, default=str)\n\ndef cf_tool_func(query_json: str) -> str:\n    payload = json.loads(query_json)\n    uid = int(payload.get('user_id'))\n    n = int(payload.get('n', 5))\n    df = get_top_n_collab(uid, n=n)\n    return df.to_json(orient='records')\n\ndef ensemble_tool_func(query_json: str) -> str:\n    payload = json.loads(query_json)\n    uid = payload.get('user_id')\n    user_prefs = payload.get('user_preferences', {})\n    top_n = int(payload.get('top_n', 5))\n    results = ensemble_recommend(user_prefs, user_id=uid, top_n=top_n)\n    return json.dumps(results, default=str)\n\ncb_tool = Tool(\n    name=\"content_based_recommender\",\n    func=cb_tool_func,\n    description=\"Given a JSON-encoded user preferences object, returns top content-based hotel recommendations.\"\n)\ncf_tool = Tool(\n    name=\"collaborative_recommender\",\n    func=cf_tool_func,\n    description=\"Given a JSON string with user_id and n, returns top-n collaborative recommendations.\"\n)\nensemble_tool = Tool(\n    name=\"ensemble_recommender\",\n    func=ensemble_tool_func,\n    description=\"Given a JSON payload containing user_id (optional) and user_preferences, returns merged recommendations.\"\n)\n\n# -------------------------\n# LLM explanation utilities (no deterministic fallback)\n# -------------------------\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import HumanMessage\nfrom google.api_core.exceptions import ResourceExhausted, NotFound\nimport traceback\n\ndef _extract_text_from_llm_response(resp):\n    \"\"\"\n    Normalize a variety of possible LangChain/LLM response shapes to extract text:\n    - If resp is a string -> return it\n    - If resp has attribute 'content' -> return resp.content\n    - If resp has attribute 'generations' -> grab first generation text\n    - If resp is a dict/list -> try to search common fields\n    \"\"\"\n    try:\n        if resp is None:\n            return \"\"\n        # plain string\n        if isinstance(resp, str):\n            return resp\n        # object with content attribute (ChatMessage-like)\n        if hasattr(resp, \"content\"):\n            return str(resp.content)\n        # LLMResult in some LangChain versions: resp.generations -> list[list[Generation]]\n        if hasattr(resp, \"generations\"):\n            gens = resp.generations\n            if isinstance(gens, list) and len(gens) > 0:\n                first = gens[0]\n                # first can be list or Generation\n                if isinstance(first, list) and len(first) > 0:\n                    g0 = first[0]\n                    if hasattr(g0, \"text\"):\n                        return str(g0.text)\n                    elif hasattr(g0, \"generation\"):\n                        return str(g0.generation)\n                else:\n                    g0 = first\n                    if hasattr(g0, \"text\"):\n                        return str(g0.text)\n                    elif hasattr(g0, \"generation\"):\n                        return str(g0.generation)\n        # dict-like\n        if isinstance(resp, dict):\n            # try common keys\n            for k in (\"text\", \"output\", \"content\", \"response\"):\n                if k in resp and resp[k]:\n                    return str(resp[k])\n            # nested possibilities\n            if \"choices\" in resp and isinstance(resp[\"choices\"], list) and len(resp[\"choices\"]) > 0:\n                ch = resp[\"choices\"][0]\n                if isinstance(ch, dict):\n                    for k in (\"text\", \"message\", \"content\"):\n                        if k in ch and ch[k]:\n                            return str(ch[k])\n        # list-like: join texts\n        if isinstance(resp, list):\n            texts = []\n            for item in resp:\n                try:\n                    texts.append(_extract_text_from_llm_response(item))\n                except Exception:\n                    continue\n            return \" \".join([t for t in texts if t])\n        # lastly, fallback to string conversion\n        return str(resp)\n    except Exception:\n        return str(resp)\n\n\nimport time\nimport random\nfrom google.api_core.exceptions import ResourceExhausted, NotFound\n\ndef generate_llm_explanations_with_retry(recs, user_prefs, model_name=\"gemini-1.5-flash\", max_tokens=120, max_retries=3):\n    \"\"\"\n    Generate LLM explanations with retry logic for rate limiting.\n    \"\"\"\n    gemini_key = os.environ.get(\"GEMINI_API_KEY\")\n    if not gemini_key:\n        for r in recs:\n            r['llm_explanation'] = \"\"\n            r['llm_error'] = \"GEMINI_API_KEY not set\"\n        return recs\n\n    try:\n        llm = ChatGoogleGenerativeAI(\n            model=model_name, \n            temperature=0.0, \n            max_output_tokens=max_tokens, \n            google_api_key=gemini_key\n        )\n    except Exception as e:\n        for r in recs:\n            r['llm_explanation'] = \"\"\n            r['llm_error'] = f\"LLM init error: {str(e)}\"\n        return recs\n\n    enriched = []\n    \n    for i, r in enumerate(recs):\n        r['llm_explanation'] = \"\"\n        r.pop('llm_error', None)\n        \n        # Add delay between requests to avoid rate limiting\n        if i > 0:\n            time.sleep(12)  # 12 second delay between requests\n        \n        retry_count = 0\n        while retry_count < max_retries:\n            try:\n                # Prepare hotel facts (same logic as before)\n                hid = None\n                try:\n                    hid = int(r.get('hotel_id'))\n                except Exception:\n                    hid = None\n\n                hotel_row = processed_data[processed_data['hotel_id'] == hid] if hid is not None else pd.DataFrame()\n                facts = {}\n                \n                if not hotel_row.empty:\n                    hr = hotel_row.iloc[0]\n                    facts['hotel_name'] = hr.get('hotel_name', r.get('hotel_name'))\n                    facts['city'] = hr.get('city', hr.get('location', r.get('city')))\n                    \n                    # Price handling\n                    facts['price'] = None\n                    for pc in ['price_per_night', 'price_per_night_inr']:\n                        if pc in hr.index and not pd.isna(hr.get(pc)):\n                            try:\n                                facts['price'] = int(hr.get(pc))\n                                break\n                            except Exception:\n                                pass\n                    \n                    facts['star_rating'] = hr.get('star_rating', hr.get('star_rating_clean', r.get('star_rating')))\n                    \n                    # Amenities\n                    amenity_cols = [c for c in processed_data.columns if str(c).startswith('amenity_')]\n                    present_amenities = []\n                    for ac in amenity_cols:\n                        try:\n                            if int(hr.get(ac, 0)) == 1:\n                                present_amenities.append(ac.replace('amenity_','').replace('_',' '))\n                        except Exception:\n                            pass\n                    facts['amenities'] = present_amenities[:4]  # Limit to 4 amenities to reduce token usage\n                else:\n                    facts['hotel_name'] = r.get('hotel_name')\n                    facts['city'] = r.get('city')\n                    facts['price'] = r.get('price_per_night')\n                    facts['star_rating'] = r.get('star_rating')\n                    facts['amenities'] = []\n\n                # Build shorter prompt to reduce token usage\n                prompt_lines = [\n                    \"Explain in 2 sentences why this hotel matches the user's preferences:\",\n                    f\"User wants: {user_prefs.get('city', 'Any city')}, budget ₹{user_prefs.get('budget_min_inr', 0)}-₹{user_prefs.get('budget_max_inr', 'unlimited')}, {user_prefs.get('min_star_rating', 'any')} stars\",\n                    f\"Hotel: {facts.get('hotel_name')} in {facts.get('city')}, ₹{facts.get('price')}/night, {facts.get('star_rating')} stars\"\n                ]\n                \n                if facts.get('amenities'):\n                    prompt_lines.append(f\"Amenities: {', '.join(facts.get('amenities')[:3])}\")\n                \n                prompt = \"\\n\".join(prompt_lines)\n\n                # Make the API call\n                human_msg = HumanMessage(content=prompt)\n                resp = llm.invoke([human_msg])\n                \n                text = _extract_text_from_llm_response(resp)\n                text = (text or \"\").strip().replace(\"\\n\", \" \")\n                \n                if text:\n                    r['llm_explanation'] = text\n                    break  # Success, exit retry loop\n                else:\n                    r['llm_explanation'] = \"\"\n                    r['llm_error'] = \"LLM returned empty response\"\n                    break\n                    \n            except ResourceExhausted as e:\n                retry_count += 1\n                if retry_count < max_retries:\n                    # Extract retry delay from error message or use exponential backoff\n                    wait_time = min(60, 5 * (2 ** retry_count) + random.uniform(0, 1))\n                    print(f\"Rate limited for hotel {r.get('hotel_id')}, waiting {wait_time:.1f}s (attempt {retry_count}/{max_retries})\")\n                    time.sleep(wait_time)\n                else:\n                    r['llm_explanation'] = \"\"\n                    r['llm_error'] = \"Rate limit exceeded after retries\"\n                    \n            except Exception as e:\n                r['llm_explanation'] = \"\"\n                r['llm_error'] = f\"LLM error: {str(e)[:100]}\"  # Truncate long error messages\n                break  # Don't retry for other errors\n        \n        enriched.append(r)\n    \n    return enriched\n\n# -------------------------\n# Example run (end-to-end)\n# -------------------------\nif __name__ == \"__main__\":\n    example_user_prefs = {\n        \"city\": \"Kolkata\",\n        \"preferred_amenities\": [\"pool\", \"gym\"],\n        \"budget_min_inr\": 1000,\n        \"budget_max_inr\": 10000,\n        \"min_star_rating\": 4\n    }\n\n    # direct ensemble call\n    ensemble_results = ensemble_recommend(example_user_prefs, user_id=1, top_n=5)\n    print(\"Ensemble results (raw):\")\n    print(json.dumps(ensemble_results, indent=2, ensure_ascii=False))\n\n    # generate explanations (LLM if GEMINI_API_KEY present, otherwise deterministic)\n    # Instead of generate_llm_explanations, use:\n    enriched_results = generate_llm_explanations_with_retry(\n                    ensemble_results, \n                    example_user_prefs, \n                    model_name=\"gemini-1.5-flash\",  # Lighter model\n                    max_tokens=80  # Reduced token limit\n    )\n    print(\"\\nEnriched results with explanations:\")\n    print(json.dumps(enriched_results, indent=2, ensure_ascii=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:28:39.448323Z","iopub.execute_input":"2025-09-08T11:28:39.448874Z","iopub.status.idle":"2025-09-08T11:29:41.629335Z","shell.execute_reply.started":"2025-09-08T11:28:39.448848Z","shell.execute_reply":"2025-09-08T11:29:41.628603Z"}},"outputs":[{"name":"stdout","text":"hotels_df: (400, 27)\nprocessed_data: (4632, 39)\nuser_hotel_interactions: (1288, 11)\nuser_profiles: (300, 16)\nEnsemble results (raw):\n[\n  {\n    \"hotel_id\": 195,\n    \"hotel_name\": \"Dover Inn By BookMeriHotel\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4300.0,\n    \"star_rating\": -1.0,\n    \"combined_score\": 0.5999999957348829,\n    \"explanation\": \"Collaborative score contribution: 1.000\"\n  },\n  {\n    \"hotel_id\": 3651,\n    \"hotel_name\": \"Kenilworth Hotel\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 6054.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.39999993296365943,\n    \"explanation\": \"Content similarity contribution: 1.000\"\n  },\n  {\n    \"hotel_id\": 416,\n    \"hotel_name\": \"The Sonnet\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4937.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.2198838038566475,\n    \"explanation\": \"Content similarity contribution: 0.550\"\n  },\n  {\n    \"hotel_id\": 2111,\n    \"hotel_name\": \"Hotel Aauris\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4650.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.17349560348062204,\n    \"explanation\": \"Content similarity contribution: 0.434\"\n  },\n  {\n    \"hotel_id\": 2119,\n    \"hotel_name\": \"Beyzaa Hotel & Suites (Brewery Hotel)\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4589.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.16363038099461868,\n    \"explanation\": \"Content similarity contribution: 0.409\"\n  }\n]\n\nEnriched results with explanations:\n[\n  {\n    \"hotel_id\": 195,\n    \"hotel_name\": \"Dover Inn By BookMeriHotel\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4300.0,\n    \"star_rating\": -1.0,\n    \"combined_score\": 0.5999999957348829,\n    \"explanation\": \"Collaborative score contribution: 1.000\",\n    \"llm_explanation\": \"This hotel doesn't match the user's preferences.  The Dover Inn is located in Kolkata and falls within the specified budget, but its star rating (-1.0) is significantly below the desired 4 stars.\"\n  },\n  {\n    \"hotel_id\": 3651,\n    \"hotel_name\": \"Kenilworth Hotel\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 6054.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.39999993296365943,\n    \"explanation\": \"Content similarity contribution: 1.000\",\n    \"llm_explanation\": \"The Kenilworth Hotel is located in Kolkata, fulfilling the user's city preference.  Its price of ₹6054 per night falls within their budget of ₹1000-₹10000, and its 4.0-star rating meets their desired star rating.\"\n  },\n  {\n    \"hotel_id\": 416,\n    \"hotel_name\": \"The Sonnet\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4937.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.2198838038566475,\n    \"explanation\": \"Content similarity contribution: 0.550\",\n    \"llm_explanation\": \"The Sonnet is located in Kolkata and falls within the user's budget of ₹1000-₹10000 per night.  Its 4.0-star rating aligns with the user's preference for a 4-star hotel.\"\n  },\n  {\n    \"hotel_id\": 2111,\n    \"hotel_name\": \"Hotel Aauris\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4650.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.17349560348062204,\n    \"explanation\": \"Content similarity contribution: 0.434\",\n    \"llm_explanation\": \"Hotel Aauris is located in Kolkata, fulfilling the user's city preference.  Its price of ₹4650 per night falls comfortably within their ₹1000-₹10000 budget and its 4.0-star rating meets their star rating requirement.\"\n  },\n  {\n    \"hotel_id\": 2119,\n    \"hotel_name\": \"Beyzaa Hotel & Suites (Brewery Hotel)\",\n    \"city\": \"Kolkata\",\n    \"price_per_night\": 4589.0,\n    \"star_rating\": 4.0,\n    \"combined_score\": 0.16363038099461868,\n    \"explanation\": \"Content similarity contribution: 0.409\",\n    \"llm_explanation\": \"The Beyzaa Hotel & Suites is located in Kolkata and falls within the user's budget of ₹1000-₹10000 per night.  Its 4.0-star rating aligns with the user's preference for a 4-star hotel.\"\n  }\n]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Save artifacts cell\nimport os\nimport json\nimport tarfile\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom surprise import Dataset, Reader, SVD\n\n# -----------------------------\n# (Re)define ContentBasedRecommender (copy from your code)\n# -----------------------------\nclass ContentBasedRecommender:\n    def __init__(self):\n        self.hotels_df = None\n        self.feature_weights = {\n            'amenities': 0.35,\n            'location': 0.25,\n            'price': 0.20,\n            'star_rating': 0.15,\n            'property_type': 0.05\n        }\n        self.amenity_features = [\n            'amenity_free_wifi', 'amenity_air_conditioning', 'amenity_parking', 'amenity_room_service',\n            'amenity_24_7_front_desk', 'amenity_restaurant', 'amenity_gym', 'amenity_pool', 'amenity_spa',\n            'amenity_business_center', 'amenity_conference_hall', 'amenity_airport_shuttle',\n            'amenity_meeting_rooms', 'amenity_vegetarian_restaurant'\n        ]\n        self.scaler = MinMaxScaler()\n\n    def load_data(self, hotels_df: pd.DataFrame):\n        self.hotels_df = hotels_df.copy()\n        for amenity in self.amenity_features:\n            if amenity in self.hotels_df.columns:\n                self.hotels_df[amenity] = self.hotels_df[amenity].fillna(0).astype(int)\n            else:\n                self.hotels_df[amenity] = 0\n\n        city_col = 'city' if 'city' in self.hotels_df.columns else ('location' if 'location' in self.hotels_df.columns else None)\n        if city_col is not None:\n            location_dummies = pd.get_dummies(self.hotels_df[city_col].fillna('Unknown'), prefix='city')\n            self.hotels_df = pd.concat([self.hotels_df, location_dummies], axis=1)\n        else:\n            location_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        price_col = 'price_per_night' if 'price_per_night' in self.hotels_df.columns else ('price_per_night_inr' if 'price_per_night_inr' in self.hotels_df.columns else 'price_per_night_inr')\n        rating_col = 'star_rating' if 'star_rating' in self.hotels_df.columns else ('star_rating_clean' if 'star_rating_clean' in self.hotels_df.columns else None)\n\n        if price_col in self.hotels_df.columns:\n            self.hotels_df[price_col] = pd.to_numeric(self.hotels_df[price_col], errors='coerce').fillna(self.hotels_df[price_col].median())\n            self.hotels_df['price_normalized'] = self.scaler.fit_transform(self.hotels_df[[price_col]])\n        else:\n            self.hotels_df['price_normalized'] = 0.0\n\n        if rating_col:\n            self.hotels_df[rating_col] = pd.to_numeric(self.hotels_df[rating_col], errors='coerce').fillna(self.hotels_df[rating_col].median())\n            self.hotels_df['rating_normalized'] = self.scaler.fit_transform(self.hotels_df[[rating_col]])\n        else:\n            self.hotels_df['rating_normalized'] = 0.0\n\n        property_col = 'hotel_type' if 'hotel_type' in self.hotels_df.columns else ('property_type' if 'property_type' in self.hotels_df.columns else None)\n        if property_col:\n            property_dummies = pd.get_dummies(self.hotels_df[property_col].fillna('Unknown'), prefix='property')\n            self.hotels_df = pd.concat([self.hotels_df, property_dummies], axis=1)\n        else:\n            property_dummies = pd.DataFrame(index=self.hotels_df.index)\n\n        self.feature_columns = (\n            self.amenity_features +\n            list(location_dummies.columns) +\n            ['price_normalized', 'rating_normalized'] +\n            list(property_dummies.columns)\n        )\n\n        for col in self.feature_columns:\n            if col not in self.hotels_df.columns:\n                self.hotels_df[col] = 0\n\n        self.hotels_df['feature_vector'] = self.hotels_df[self.feature_columns].values.tolist()\n        return self\n\n# -----------------------------\n# Paths (use exactly your provided Kaggle input paths)\n# -----------------------------\nINPUT_HOTELS = \"/kaggle/input/hotel-master/hotels_master.csv\"\nINPUT_PROCESSED = \"/kaggle/input/preprocessed-data/preprocessed_hotel_data_final_new.csv\"\nINPUT_INTERACTIONS = \"/kaggle/input/user-hotel-interactions/user_hotel_interactions.csv\"\nINPUT_PROFILES = \"/kaggle/input/user-profiles/user_profiles.csv\"\n\nOUT_DIR = \"/kaggle/working/recommender_artifacts\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# -----------------------------\n# 1) Load all CSVs (exact files you specified)\n# -----------------------------\nprint(\"Reading input CSVs...\")\nhotels_df = pd.read_csv(INPUT_HOTELS)\nprocessed_data = pd.read_csv(INPUT_PROCESSED)\nuser_hotel_interactions = pd.read_csv(INPUT_INTERACTIONS)\nuser_profiles = pd.read_csv(INPUT_PROFILES)\n\nprint(\"hotels_df:\", hotels_df.shape)\nprint(\"processed_data:\", processed_data.shape)\nprint(\"user_hotel_interactions:\", user_hotel_interactions.shape)\nprint(\"user_profiles:\", user_profiles.shape)\n\n# -----------------------------\n# 2) Initialize / fit ContentBasedRecommender on processed_data\n# -----------------------------\nprint(\"Building ContentBasedRecommender and feature vectors...\")\ncb_recommender = ContentBasedRecommender()\ncb_recommender.load_data(processed_data)\n\n# -----------------------------\n# 3) Train Surprise SVD collaborative model (using user_hotel_interactions)\n# -----------------------------\nprint(\"Preparing collaborative dataset and training SVD (this may take a moment)...\")\n# Ensure rating numeric\nuser_hotel_interactions['rating'] = pd.to_numeric(user_hotel_interactions.get('rating', 0), errors='coerce').fillna(0)\n\n# Surprise dataset expects user, item, rating columns\nfrom surprise import Dataset, Reader, SVD\nreader = Reader(rating_scale=(0, 5))\nsvd_data = Dataset.load_from_df(user_hotel_interactions[['user_id', 'hotel_id', 'rating']], reader)\nsvd_algo = SVD(n_factors=50, random_state=42)\ntrainset = svd_data.build_full_trainset()\nsvd_algo.fit(trainset)\nprint(\"SVD training finished.\")\n\n# -----------------------------\n# 4) Create hotel mapping and lists\n# -----------------------------\nhotel_mapping = processed_data[['hotel_id', 'hotel_name']].drop_duplicates()\nall_hotels = processed_data['hotel_id'].unique().tolist()\n\n# -----------------------------\n# 5) Save artifacts\n# -----------------------------\nprint(\"Saving artifacts to:\", OUT_DIR)\n\n# Save copies of CSVs\nprocessed_csv_out = os.path.join(OUT_DIR, \"processed_data.csv\")\nhotels_csv_out = os.path.join(OUT_DIR, \"hotels_master.csv\")\ninteractions_csv_out = os.path.join(OUT_DIR, \"user_hotel_interactions.csv\")\nprofiles_csv_out = os.path.join(OUT_DIR, \"user_profiles.csv\")\n\nprocessed_data.to_csv(processed_csv_out, index=False)\nhotels_df.to_csv(hotels_csv_out, index=False)\nuser_hotel_interactions.to_csv(interactions_csv_out, index=False)\nuser_profiles.to_csv(profiles_csv_out, index=False)\nhotel_mapping.to_csv(os.path.join(OUT_DIR, \"hotel_mapping.csv\"), index=False)\n\nprint(\"Saved CSV copies.\")\n\n# Save SVD model (joblib)\nsvd_path = os.path.join(OUT_DIR, \"svd_model.joblib\")\njoblib.dump(svd_algo, svd_path)\nprint(\"Saved SVD model ->\", svd_path)\n\n# Save content-based recommender (joblib)\ncb_path = os.path.join(OUT_DIR, \"cb_recommender.joblib\")\ntry:\n    joblib.dump(cb_recommender, cb_path)\n    print(\"Saved ContentBasedRecommender ->\", cb_path)\nexcept Exception as e:\n    # If pickling the entire instance fails, fallback: save the feature_columns and rely on CSV for rebuilding\n    print(\"Warning: failed to joblib.dump(cb_recommender):\", e)\n    cb_path = None\n\n# Save metadata (feature columns, amenity list, all_hotels)\nmeta = {\n    \"feature_columns\": getattr(cb_recommender, \"feature_columns\", None),\n    \"amenity_features\": getattr(cb_recommender, \"amenity_features\", None),\n    \"all_hotels\": all_hotels\n}\nmeta_path = os.path.join(OUT_DIR, \"metadata.json\")\nwith open(meta_path, \"w\") as f:\n    json.dump(meta, f, indent=2)\nprint(\"Saved metadata ->\", meta_path)\n\n# Create tarball for easy download\ntar_path = os.path.join(\"/kaggle/working\", \"recommender_artifacts.tar.gz\")\nwith tarfile.open(tar_path, \"w:gz\") as tar:\n    tar.add(OUT_DIR, arcname=os.path.basename(OUT_DIR))\nprint(\"Created tarball ->\", tar_path)\n\nprint(\"Done. You can download these files from the Kaggle 'Files' panel:\")\nfor p in [processed_csv_out, hotels_csv_out, interactions_csv_out, profiles_csv_out, svd_path, cb_path, meta_path, tar_path]:\n    if p:\n        print(\" -\", p)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:18:38.312729Z","iopub.execute_input":"2025-09-08T10:18:38.313337Z","iopub.status.idle":"2025-09-08T10:18:38.841145Z","shell.execute_reply.started":"2025-09-08T10:18:38.313312Z","shell.execute_reply":"2025-09-08T10:18:38.840551Z"}},"outputs":[{"name":"stdout","text":"Reading input CSVs...\nhotels_df: (400, 27)\nprocessed_data: (4632, 39)\nuser_hotel_interactions: (1288, 11)\nuser_profiles: (300, 16)\nBuilding ContentBasedRecommender and feature vectors...\nPreparing collaborative dataset and training SVD (this may take a moment)...\nSVD training finished.\nSaving artifacts to: /kaggle/working/recommender_artifacts\nSaved CSV copies.\nSaved SVD model -> /kaggle/working/recommender_artifacts/svd_model.joblib\nSaved ContentBasedRecommender -> /kaggle/working/recommender_artifacts/cb_recommender.joblib\nSaved metadata -> /kaggle/working/recommender_artifacts/metadata.json\nCreated tarball -> /kaggle/working/recommender_artifacts.tar.gz\nDone. You can download these files from the Kaggle 'Files' panel:\n - /kaggle/working/recommender_artifacts/processed_data.csv\n - /kaggle/working/recommender_artifacts/hotels_master.csv\n - /kaggle/working/recommender_artifacts/user_hotel_interactions.csv\n - /kaggle/working/recommender_artifacts/user_profiles.csv\n - /kaggle/working/recommender_artifacts/svd_model.joblib\n - /kaggle/working/recommender_artifacts/cb_recommender.joblib\n - /kaggle/working/recommender_artifacts/metadata.json\n - /kaggle/working/recommender_artifacts.tar.gz\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import sys\nimport platform\nimport importlib\n\n# List of packages you want to check versions for\npackages = [\n    \"pandas\",\n    \"numpy\",\n    \"scikit-learn\",\n    \"scipy\",\n    \"surprise\",\n    \"joblib\",\n    \"fastapi\",\n    \"uvicorn\",\n    \"langchain\",\n    \"langchain_google_genai\",\n    \"google_api_core\"\n]\n\nprint(\"=\"*40)\nprint(\"Python:\", sys.version)\nprint(\"Platform:\", platform.platform())\nprint(\"=\"*40)\n\nfor pkg in packages:\n    try:\n        module = importlib.import_module(pkg.replace(\"-\", \"_\"))\n        version = getattr(module, \"__version__\", \"unknown\")\n        print(f\"{pkg:25s} {version}\")\n    except ImportError:\n        print(f\"{pkg:25s} NOT INSTALLED\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:30:11.785331Z","iopub.execute_input":"2025-09-08T11:30:11.785852Z","iopub.status.idle":"2025-09-08T11:30:12.169490Z","shell.execute_reply.started":"2025-09-08T11:30:11.785828Z","shell.execute_reply":"2025-09-08T11:30:12.168770Z"}},"outputs":[{"name":"stdout","text":"========================================\nPython: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPlatform: Linux-6.6.56+-x86_64-with-glibc2.35\n========================================\npandas                    2.2.3\nnumpy                     1.26.4\nscikit-learn              NOT INSTALLED\nscipy                     1.15.3\nsurprise                  1.1.4\njoblib                    1.5.1\nfastapi                   0.115.13\nuvicorn                   0.34.3\nlangchain                 0.3.27\nlangchain_google_genai    unknown\ngoogle_api_core           NOT INSTALLED\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}