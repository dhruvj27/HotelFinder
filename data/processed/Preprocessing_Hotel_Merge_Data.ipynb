{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2602633-0038-4795-a2ff-6e1b7f4bad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.2)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (4632, 29)\n",
      "Initial columns: ['hotel_name', 'rating', 'rating_description', 'review_count', 'star_rating', 'location', 'nearest_landmark', 'Distance_to_Landmark', 'Distance_to_Landmark(in_km)', 'price_per_night', 'tax', 'city', 'state', 'address', 'price_range', 'latitude', 'longitude', 'amenities', 'hotel_type', 'phone_number', 'email', 'website', 'booking_url', 'description', 'check_in_time', 'check_out_time', 'room_types', 'data_source', 'data_quality_score']\n",
      "After dropping columns: (4632, 20)\n",
      "Found 19 common amenities (appearing ≥10 times):\n",
      "  Free WiFi: 3943 occurrences\n",
      "  Air Conditioning: 3924 occurrences\n",
      "  24/7 Front Desk: 3794 occurrences\n",
      "  Spa: 498 occurrences\n",
      "  Pool: 453 occurrences\n",
      "  Gym: 660 occurrences\n",
      "  Restaurant: 673 occurrences\n",
      "  Room Service: 404 occurrences\n",
      "  Business Center: 141 occurrences\n",
      "  Meeting Rooms: 145 occurrences\n",
      "  Bar: 65 occurrences\n",
      "  Swimming Pool: 53 occurrences\n",
      "  Parking: 58 occurrences\n",
      "  Travel Desk: 56 occurrences\n",
      "  Airport Shuttle: 110 occurrences\n",
      "  Conference Hall: 96 occurrences\n",
      "  Laundry Service: 64 occurrences\n",
      "  Valet Parking: 57 occurrences\n",
      "  Concierge: 42 occurrences\n",
      "Final dataset shape: (4632, 40)\n",
      "Final columns: 40\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4632 entries, 0 to 4631\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   hotel_name                   4632 non-null   object \n",
      " 1   rating                       4632 non-null   float64\n",
      " 2   rating_description           4632 non-null   object \n",
      " 3   review_count                 4632 non-null   float64\n",
      " 4   star_rating                  4632 non-null   float64\n",
      " 5   location                     4632 non-null   object \n",
      " 6   nearest_landmark             4632 non-null   object \n",
      " 7   Distance_to_Landmark(in_km)  4632 non-null   float64\n",
      " 8   price_per_night              4632 non-null   float64\n",
      " 9   tax                          4632 non-null   float64\n",
      " 10  city                         4632 non-null   object \n",
      " 11  state                        4632 non-null   object \n",
      " 12  price_range                  4632 non-null   object \n",
      " 13  latitude                     4632 non-null   float64\n",
      " 14  longitude                    4632 non-null   float64\n",
      " 15  hotel_type                   4632 non-null   object \n",
      " 16  room_types                   4632 non-null   object \n",
      " 17  data_quality_score           4632 non-null   float64\n",
      " 18  star_rating_clean            4632 non-null   object \n",
      " 19  has_coordinates              4632 non-null   int64  \n",
      " 20  amenity_free_wifi            4632 non-null   int64  \n",
      " 21  amenity_air_conditioning     4632 non-null   int64  \n",
      " 22  amenity_24_7_front_desk      4632 non-null   int64  \n",
      " 23  amenity_spa                  4632 non-null   int64  \n",
      " 24  amenity_pool                 4632 non-null   int64  \n",
      " 25  amenity_gym                  4632 non-null   int64  \n",
      " 26  amenity_restaurant           4632 non-null   int64  \n",
      " 27  amenity_room_service         4632 non-null   int64  \n",
      " 28  amenity_business_center      4632 non-null   int64  \n",
      " 29  amenity_meeting_rooms        4632 non-null   int64  \n",
      " 30  amenity_bar                  4632 non-null   int64  \n",
      " 31  amenity_swimming_pool        4632 non-null   int64  \n",
      " 32  amenity_parking              4632 non-null   int64  \n",
      " 33  amenity_travel_desk          4632 non-null   int64  \n",
      " 34  amenity_airport_shuttle      4632 non-null   int64  \n",
      " 35  amenity_conference_hall      4632 non-null   int64  \n",
      " 36  amenity_laundry_service      4632 non-null   int64  \n",
      " 37  amenity_valet_parking        4632 non-null   int64  \n",
      " 38  amenity_concierge            4632 non-null   int64  \n",
      " 39  total_amenities_count        4632 non-null   int64  \n",
      "dtypes: float64(9), int64(21), object(10)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Data types:\n",
      "int64      21\n",
      "object     10\n",
      "float64     9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_merged_sheet.csv')\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Initial columns:\", df.columns.tolist())\n",
    "\n",
    "# --- 1. DROP UNNECESSARY COLUMNS ---\n",
    "cols_to_drop = [\n",
    "    'check_in_time', 'check_out_time', 'phone_number', 'email', \n",
    "    'website', 'booking_url', 'data_source', 'address', \n",
    "    'Distance_to_Landmark'  # Drop text version, keep Distance_to_Landmark(in_km)\n",
    "]\n",
    "df_clean = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "print(f\"After dropping columns: {df_clean.shape}\")\n",
    "\n",
    "# --- 2. CLEAN CITY AND STATE COLUMNS ---\n",
    "# Fill missing city/state values\n",
    "df_clean['city'] = df_clean['city'].fillna('Unknown')\n",
    "df_clean['state'] = df_clean['state'].fillna('Unknown')\n",
    "\n",
    "# Convert to string to ensure consistency\n",
    "df_clean['city'] = df_clean['city'].astype(str)\n",
    "df_clean['state'] = df_clean['state'].astype(str)\n",
    "\n",
    "# Clean any coordinate values that might be in city/state columns\n",
    "df_clean['city'] = df_clean['city'].apply(\n",
    "    lambda x: 'Unknown' if (isinstance(x, str) and \n",
    "                           (x.replace('.', '').replace('-', '').isdigit() or \n",
    "                            len(x) > 20)) else x\n",
    ")\n",
    "df_clean['state'] = df_clean['state'].apply(\n",
    "    lambda x: 'Unknown' if (isinstance(x, str) and \n",
    "                           (x.replace('.', '').replace('-', '').isdigit() or \n",
    "                            len(x) > 20)) else x\n",
    ")\n",
    "\n",
    "# --- 3. HANDLE MISSING VALUES ---\n",
    "\n",
    "# A. Numerical columns - fill with median\n",
    "numerical_cols = ['rating', 'review_count', 'price_per_night', 'tax', 'guest_rating']\n",
    "for col in numerical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# B. Star rating - keep as Unknown for missing values\n",
    "df_clean['star_rating'] = df_clean['star_rating'].fillna(-1)  # Use -1 for Unknown\n",
    "df_clean['star_rating_clean'] = df_clean['star_rating'].apply(\n",
    "    lambda x: 'Unknown' if x == -1 else str(int(x))\n",
    ")\n",
    "\n",
    "# C. Categorical columns\n",
    "categorical_cols = ['rating_description', 'nearest_landmark', 'price_range', \n",
    "                   'location', 'hotel_type', 'room_types']\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "\n",
    "# D. Distance column - fill missing with -1 for unknown\n",
    "if 'Distance_to_Landmark(in_km)' in df_clean.columns:\n",
    "    df_clean['Distance_to_Landmark(in_km)'] = df_clean['Distance_to_Landmark(in_km)'].fillna(-1)\n",
    "\n",
    "# E. Coordinates - fill with India center coordinates\n",
    "if 'latitude' in df_clean.columns and 'longitude' in df_clean.columns:\n",
    "    # Option 1: Create a flag for missing coordinates\n",
    "    df_clean['has_coordinates'] = (~df_clean['latitude'].isna() & ~df_clean['longitude'].isna()).astype(int)\n",
    "    \n",
    "    # Option 2: Drop coordinate columns if too many missing values (>50%)\n",
    "    lat_missing_pct = df_clean['latitude'].isna().mean()\n",
    "    lon_missing_pct = df_clean['longitude'].isna().mean()\n",
    "    \n",
    "    if lat_missing_pct > 0.5 or lon_missing_pct > 0.5:\n",
    "        print(f\"Dropping coordinates due to high missingness: lat={lat_missing_pct:.1%}, lon={lon_missing_pct:.1%}\")\n",
    "        df_clean = df_clean.drop(columns=['latitude', 'longitude'])\n",
    "    else:\n",
    "        # If keeping coordinates, fill with median of available coordinates\n",
    "        df_clean['latitude'] = df_clean['latitude'].fillna(df_clean['latitude'].median())\n",
    "        df_clean['longitude'] = df_clean['longitude'].fillna(df_clean['longitude'].median())\n",
    "\n",
    "# F. Handle amenities - automated extraction\n",
    "def extract_all_amenities(amenities_str):\n",
    "    if pd.isna(amenities_str) or amenities_str == '':\n",
    "        return []\n",
    "    \n",
    "    # Split by comma and clean each amenity\n",
    "    amenities_list = [a.strip() for a in str(amenities_str).split(',')]\n",
    "    return amenities_list\n",
    "\n",
    "if 'amenities' in df_clean.columns:\n",
    "    df_clean['amenities'] = df_clean['amenities'].fillna('')\n",
    "    \n",
    "    # Extract all individual amenities\n",
    "    all_amenities_lists = df_clean['amenities'].apply(extract_all_amenities)\n",
    "    \n",
    "    # Flatten the list of lists and get unique amenities\n",
    "    all_individual_amenities = []\n",
    "    for amenity_list in all_amenities_lists:\n",
    "        all_individual_amenities.extend(amenity_list)\n",
    "    \n",
    "    # Get unique amenities and their frequencies\n",
    "    from collections import Counter\n",
    "    amenity_counter = Counter(all_individual_amenities)\n",
    "    \n",
    "    # Get the most common amenities (let's take those that appear at least 10 times)\n",
    "    common_amenities = [amenity for amenity, count in amenity_counter.items() if count >= 10]\n",
    "    \n",
    "    print(f\"Found {len(common_amenities)} common amenities (appearing ≥10 times):\")\n",
    "    for amenity in common_amenities:\n",
    "        print(f\"  {amenity}: {amenity_counter[amenity]} occurrences\")\n",
    "    \n",
    "    # Create binary columns for each common amenity\n",
    "    for amenity in common_amenities:\n",
    "        # Create a clean column name\n",
    "        col_name = f\"amenity_{amenity.lower().replace(' ', '_').replace('/', '_').replace('-', '_')}\"\n",
    "        col_name = col_name.replace('__', '_').strip('_')\n",
    "        \n",
    "        df_clean[col_name] = all_amenities_lists.apply(lambda x: 1 if amenity in x else 0)\n",
    "    \n",
    "    # Count total amenities\n",
    "    df_clean['total_amenities_count'] = all_amenities_lists.apply(len)\n",
    "    \n",
    "    # Drop original amenities column\n",
    "    df_clean = df_clean.drop(columns=['amenities'])\n",
    "\n",
    "# G. Description - drop this column as requested (TF-IDF gives unwanted results)\n",
    "if 'description' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['description'])\n",
    "\n",
    "# H. Data quality score - keep as is if exists\n",
    "if 'data_quality_score' in df_clean.columns:\n",
    "    df_clean['data_quality_score'] = df_clean['data_quality_score'].fillna(df_clean['data_quality_score'].median())\n",
    "\n",
    "# --- 4. ENCODE CATEGORICAL VARIABLES (SMART APPROACH) ---\n",
    "\n",
    "# For high cardinality categoricals like city/state, use label encoding\n",
    "# For low cardinality ones, use one-hot encoding\n",
    "\n",
    "\"\"\"\"high_cardinality_cols = ['city', 'state', 'hotel_name', 'location', 'nearest_landmark']\n",
    "low_cardinality_cols = ['rating_description', 'price_range','hotel_type', 'room_types', 'star_rating_clean']\n",
    "\n",
    "# Store all encoding mappings\n",
    "encoding_mappings = {}\n",
    "\n",
    "# Label encoding for high cardinality\n",
    "label_encoders = {}\n",
    "for col in high_cardinality_cols:\n",
    "    if col in df_clean.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_clean[f'{col}_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        # Store the mapping\n",
    "        encoding_mappings[col] = {\n",
    "            'encoding_type': 'label_encoding',\n",
    "            'mapping': {int(i): str(value) for i, value in enumerate(le.classes_)}\n",
    "        }\n",
    "\n",
    "# One-hot encoding for low cardinality (limit categories)\n",
    "one_hot_mappings = {}\n",
    "for col in low_cardinality_cols:\n",
    "    if col in df_clean.columns:\n",
    "        # Limit to top categories to avoid explosion\n",
    "        value_counts = df_clean[col].value_counts()\n",
    "        top_categories = value_counts[value_counts > 10].index  # Only keep categories with more than 10 occurrences\n",
    "        \n",
    "        if len(top_categories) > 0:\n",
    "            df_clean[col] = df_clean[col].apply(\n",
    "                lambda x: x if x in top_categories else 'Other'\n",
    "            )\n",
    "            \n",
    "            # Store the one-hot mapping\n",
    "            one_hot_mappings[col] = {\n",
    "                'encoding_type': 'one_hot_encoding',\n",
    "                'categories': list(df_clean[col].unique())\n",
    "            }\n",
    "            \n",
    "            # One-hot encode\n",
    "            dummies = pd.get_dummies(df_clean[col], prefix=col)\n",
    "            df_clean = pd.concat([df_clean, dummies], axis=1)\n",
    "\n",
    "# Add one-hot mappings to the main encoding mappings\n",
    "encoding_mappings.update(one_hot_mappings)\n",
    "\n",
    "# Drop original categorical columns (keep the encoded versions)\n",
    "categorical_to_drop = high_cardinality_cols + low_cardinality_cols + ['star_rating']\n",
    "df_clean = df_clean.drop(columns=[col for col in categorical_to_drop if col in df_clean.columns])\"\"\"\n",
    "\n",
    "# --- 5. FINAL CLEANUP (NO SCALING - as requested) ---\n",
    "# Remove any constant columns\n",
    "df_clean = df_clean.loc[:, df_clean.nunique() > 1]\n",
    "\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"Final columns: {len(df_clean.columns)}\")\n",
    "\n",
    "# Display info about the cleaned dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df_clean.info())\n",
    "\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_counts = df_clean.isnull().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df_clean.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2983b7b-f5af-45e7-a297-fdf835e3b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random hotel IDs from 1 to the number of rows\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_ids = np.random.permutation(len(df_clean)) + 1\n",
    "\n",
    "# Add hotel_id column with random IDs\n",
    "df_clean.insert(1, 'hotel_id', random_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cea969-1728-4466-8106-ca06a69e6a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hotel_name', 'hotel_id', 'rating', 'rating_description',\n",
       "       'review_count', 'star_rating', 'location', 'nearest_landmark',\n",
       "       'Distance_to_Landmark(in_km)', 'price_per_night', 'tax', 'city',\n",
       "       'state', 'price_range', 'latitude', 'longitude', 'hotel_type',\n",
       "       'room_types', 'data_quality_score', 'star_rating_clean',\n",
       "       'has_coordinates', 'amenity_free_wifi', 'amenity_air_conditioning',\n",
       "       'amenity_24_7_front_desk', 'amenity_spa', 'amenity_pool', 'amenity_gym',\n",
       "       'amenity_restaurant', 'amenity_room_service', 'amenity_business_center',\n",
       "       'amenity_meeting_rooms', 'amenity_bar', 'amenity_swimming_pool',\n",
       "       'amenity_parking', 'amenity_travel_desk', 'amenity_airport_shuttle',\n",
       "       'amenity_conference_hall', 'amenity_laundry_service',\n",
       "       'amenity_valet_parking', 'amenity_concierge', 'total_amenities_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b15c395-7d1f-499d-a615-eab0c54e1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop([\"amenity_laundry_service\", \"amenity_concierge\"], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9309a55-1cdc-443a-b465-03482e27128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed data saved as 'preprocessed_hotel_data_final_new.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed data\n",
    "df_clean.to_csv('preprocessed_hotel_data_final_new.csv', index=False)\n",
    "print(\"\\nPreprocessed data saved as 'preprocessed_hotel_data_final_new.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0efe521-c00d-4517-b452-54bf22a3b757",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 48) (1893385018.py, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 48\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 48)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "# Save encoding mappings to a separate JSON file\n",
    "with open('encoding_mappings.json', 'w') as f:\n",
    "    json.dump(encoding_mappings, f, indent=2)\n",
    "print(\"Encoding mappings saved as 'encoding_mappings.json'\")\n",
    "\n",
    "# Show sample of the processed data\n",
    "print(f\"\\nSample of processed data:\")\n",
    "print(df_clean.head())\n",
    "\n",
    "# Show encoding mappings for reference\n",
    "print(\"\\nEncoding mappings:\")\n",
    "for col, mapping_info in encoding_mappings.items():\n",
    "    print(f\"\\n{col} encoding ({mapping_info['encoding_type']}):\")\n",
    "    if mapping_info['encoding_type'] == 'label_encoding':\n",
    "        for code, value in list(mapping_info['mapping'].items())[:10]:  # Show first 10\n",
    "            print(f\"  {code}: {value}\")\n",
    "        if len(mapping_info['mapping']) > 10:\n",
    "            print(f\"  ... and {len(mapping_info['mapping']) - 10} more\")\n",
    "    else:  # one_hot_encoding\n",
    "        print(f\"  Categories: {', '.join(mapping_info['categories'][:10])}\")\n",
    "        if len(mapping_info['categories']) > 10:\n",
    "            print(f\"  ... and {len(mapping_info['categories']) - 10} more\")\n",
    "\n",
    "# Also create a CSV version of the mappings for easier reading\n",
    "mappings_df_data = []\n",
    "for col, mapping_info in encoding_mappings.items():\n",
    "    if mapping_info['encoding_type'] == 'label_encoding':\n",
    "        for code, value in mapping_info['mapping'].items():\n",
    "            mappings_df_data.append({\n",
    "                'column': col,\n",
    "                'encoding_type': 'label_encoding',\n",
    "                'encoded_value': code,\n",
    "                'original_value': value\n",
    "            })\n",
    "    else:  # one_hot_encoding\n",
    "        for category in mapping_info['categories']:\n",
    "            mappings_df_data.append({\n",
    "                'column': col,\n",
    "                'encoding_type': 'one_hot_encoding',\n",
    "                'encoded_value': f\"{col}_{category}\",\n",
    "                'original_value': category\n",
    "            })\n",
    "\n",
    "mappings_df = pd.DataFrame(mappings_df_data)\n",
    "mappings_df.to_csv('encoding_mappings_detailed.csv', index=False)\n",
    "print(\"Detailed encoding mappings saved as 'encoding_mappings_detailed.csv'\")\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d29ef4-97d4-4baa-a923-b87d0efb309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hotel_name', 'hotel_id', 'rating', 'rating_description',\n",
       "       'review_count', 'star_rating', 'location', 'nearest_landmark',\n",
       "       'Distance_to_Landmark(in_km)', 'price_per_night', 'tax', 'city',\n",
       "       'state', 'price_range', 'latitude', 'longitude', 'hotel_type',\n",
       "       'room_types', 'data_quality_score', 'star_rating_clean',\n",
       "       'has_coordinates', 'amenity_free_wifi', 'amenity_air_conditioning',\n",
       "       'amenity_24_7_front_desk', 'amenity_spa', 'amenity_pool', 'amenity_gym',\n",
       "       'amenity_restaurant', 'amenity_room_service', 'amenity_business_center',\n",
       "       'amenity_meeting_rooms', 'amenity_bar', 'amenity_swimming_pool',\n",
       "       'amenity_parking', 'amenity_travel_desk', 'amenity_airport_shuttle',\n",
       "       'amenity_conference_hall', 'amenity_valet_parking',\n",
       "       'total_amenities_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efff543-eae8-47f1-8bea-663a137cb50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
